{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Least squares and linear basis functions models\n",
    "## 1.1 Least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def least_squares(y, tx):\n",
    "    \"\"\"calculate the least squares solution.\"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # least squares: TODO\n",
    "    # returns mse, and optimal weights\n",
    "    # ***************************************************\n",
    "    n, _ = np.shape(tx)\n",
    "    w = np.matmul(np.linalg.inv(np.matmul((tx.T), tx)), tx.T).dot(y)\n",
    "    error = np.sum(np.square(y - tx.dot(w))) / (2*n)\n",
    "    return error, w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data\n",
    "Here we will reuse the dataset `height_weight_genders.csv` from previous exercise section to check the correctness of your implementation. Please compare it with your previous result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "def test_your_least_squares():\n",
    "    height, weight, gender = load_data_from_ex02(sub_sample=False, add_outlier=False)\n",
    "    x, mean_x, std_x = standardize(height)\n",
    "    y, tx = build_model_data(x, weight)\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # least square or grid search: TODO\n",
    "    # this code should compare the optimal weights obtained \n",
    "    # by least squares vs. grid search\n",
    "    # ***************************************************\n",
    "    print('shape of y is: ', np.shape(y))\n",
    "    print('shape of tx is:', np.shape(tx))\n",
    "    loss_mse, w_opt = least_squares(y, tx)\n",
    "    print(loss_mse, w_opt)\n",
    "    from gradient_descent import gradient_descent\n",
    "    max_iter = 1000\n",
    "    w_init = np.asarray([70, 20])\n",
    "    gamma = 0.01\n",
    "    loss_gd, w_gd = gradient_descent(y, tx, w_init, max_iter, gamma)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test it here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of y is:  (10000,)\n",
      "shape of tx is: (10000, 2)\n",
      "15.3858878688294 [73.293922   13.47971243]\n",
      "Gradient Descent(0/999): loss=42.06792391202398, w0=70.03293922002105, w1=19.934797124349892\n",
      "Gradient Descent(1/999): loss=41.53695139476443, w0=70.06554904784188, w1=19.870246277456282\n",
      "Gradient Descent(2/999): loss=41.016545230598325, w0=70.09783277738451, w1=19.80634093903161\n",
      "Gradient Descent(3/999): loss=40.50649514909915, w0=70.12979366963172, w1=19.743074653991183\n",
      "Gradient Descent(4/999): loss=40.006595064221756, w0=70.16143495295645, w1=19.680441031801163\n",
      "Gradient Descent(5/999): loss=39.516642991033464, w0=70.19275982344794, w1=19.61843374583304\n",
      "Gradient Descent(6/999): loss=39.036440964101594, w0=70.22377144523452, w1=19.557046532724602\n",
      "Gradient Descent(7/999): loss=38.56579495750568, w0=70.25447295080322, w1=19.496273191747246\n",
      "Gradient Descent(8/999): loss=38.10451480644103, w0=70.28486744131624, w1=19.436107584179663\n",
      "Gradient Descent(9/999): loss=37.65241413038255, w0=70.31495798692413, w1=19.376543632687756\n",
      "Gradient Descent(10/999): loss=37.209310257777645, w0=70.34474762707593, w1=19.31757532071077\n",
      "Gradient Descent(11/999): loss=36.7750241522376, w0=70.37423937082623, w1=19.259196691853553\n",
      "Gradient Descent(12/999): loss=36.34938034019776, w0=70.40343619713902, w1=19.20140184928491\n",
      "Gradient Descent(13/999): loss=35.93220684001756, w0=70.43234105518867, w1=19.144184955141952\n",
      "Gradient Descent(14/999): loss=35.52333509249093, w0=70.46095686465783, w1=19.087540229940423\n",
      "Gradient Descent(15/999): loss=35.12259989274008, w0=70.48928651603231, w1=19.03146195199091\n",
      "Gradient Descent(16/999): loss=34.729839323464255, w0=70.51733287089304, w1=18.97594445682089\n",
      "Gradient Descent(17/999): loss=34.344894689517005, w0=70.54509876220517, w1=18.92098213660257\n",
      "Gradient Descent(18/999): loss=33.96761045378529, w0=70.57258699460417, w1=18.866569439586435\n",
      "Gradient Descent(19/999): loss=33.597834174344676, w0=70.59980034467918, w1=18.81270086954046\n",
      "Gradient Descent(20/999): loss=33.2354164428649, w0=70.62674156125344, w1=18.759370985194945\n",
      "Gradient Descent(21/999): loss=32.8802108242416, w0=70.65341336566196, w1=18.706574399692887\n",
      "Gradient Descent(22/999): loss=32.532073797428886, w0=70.6798184520264, w1=18.65430578004585\n",
      "Gradient Descent(23/999): loss=32.19086469744976, w0=70.70595948752718, w1=18.60255984659528\n",
      "Gradient Descent(24/999): loss=31.856445658560215, w0=70.73183911267296, w1=18.55133137247922\n",
      "Gradient Descent(25/999): loss=31.528681558544584, w0=70.75745994156728, w1=18.500615183104316\n",
      "Gradient Descent(26/999): loss=31.207439964119256, w0=70.78282456217265, w1=18.450406155623163\n",
      "Gradient Descent(27/999): loss=30.892591077423003, w0=70.80793553657197, w1=18.400699218416822\n",
      "Gradient Descent(28/999): loss=30.584007683571993, w0=70.8327954012273, w1=18.351489350582543\n",
      "Gradient Descent(29/999): loss=30.28156509925863, w0=70.85740666723608, w1=18.302771581426608\n",
      "Gradient Descent(30/999): loss=29.985141122373083, w0=70.88177182058477, w1=18.254540989962234\n",
      "Gradient Descent(31/999): loss=29.694615982627553, w0=70.90589332239998, w1=18.2067927044125\n",
      "Gradient Descent(32/999): loss=29.409872293162973, w0=70.92977360919703, w1=18.159521901718264\n",
      "Gradient Descent(33/999): loss=29.13079500311873, w0=70.95341509312611, w1=18.112723807050973\n",
      "Gradient Descent(34/999): loss=28.857271351146373, w0=70.9768201622159, w1=18.066393693330355\n",
      "Gradient Descent(35/999): loss=28.58919081984827, w0=70.9999911806148, w1=18.020526880746942\n",
      "Gradient Descent(36/999): loss=28.326445091122988, w0=71.0229304888297, w1=17.975118736289364\n",
      "Gradient Descent(37/999): loss=28.068928002399353, w0=71.04564040396245, w1=17.930164673276362\n",
      "Gradient Descent(38/999): loss=27.816535503741324, w0=71.06812321994389, w1=17.88566015089349\n",
      "Gradient Descent(39/999): loss=27.569165615806565, w0=71.0903812077655, w1=17.841600673734444\n",
      "Gradient Descent(40/999): loss=27.32671838864171, w0=71.1124166157089, w1=17.79798179134699\n",
      "Gradient Descent(41/999): loss=27.089095861297455, w0=71.13423166957286, w1=17.754799097783412\n",
      "Gradient Descent(42/999): loss=26.85620202224734, w0=71.15582857289817, w1=17.712048231155467\n",
      "Gradient Descent(43/999): loss=26.62794277059434, w0=71.17720950719024, w1=17.669724873193804\n",
      "Gradient Descent(44/999): loss=26.404225878049225, w0=71.19837663213939, w1=17.627824748811758\n",
      "Gradient Descent(45/999): loss=26.184960951665765, w0=71.21933208583904, w1=17.586343625673532\n",
      "Gradient Descent(46/999): loss=25.970059397317332, w0=71.2400779850017, w1=17.545277313766686\n",
      "Gradient Descent(47/999): loss=25.759434383900416, w0=71.26061642517274, w1=17.50462166497891\n",
      "Gradient Descent(48/999): loss=25.553000808250495, w0=71.28094948094207, w1=17.46437257267901\n",
      "Gradient Descent(49/999): loss=25.350675260756006, w0=71.3010792061537, w1=17.42452597130211\n",
      "Gradient Descent(50/999): loss=25.152375991656662, w0=71.32100763411322, w1=17.38507783593898\n",
      "Gradient Descent(51/999): loss=24.958022878012404, w0=71.34073677779314, w1=17.34602418192948\n",
      "Gradient Descent(52/999): loss=24.76753739132965, w0=71.36026863003626, w1=17.307361064460075\n",
      "Gradient Descent(53/999): loss=24.580842565831894, w0=71.37960516375695, w1=17.269084578165366\n",
      "Gradient Descent(54/999): loss=24.397862967361544, w0=71.39874833214043, w1=17.2311908567336\n",
      "Gradient Descent(55/999): loss=24.21852466290076, w0=71.41770006884008, w1=17.193676072516155\n",
      "Gradient Descent(56/999): loss=24.04275519069874, w0=71.43646228817273, w1=17.156536436140883\n",
      "Gradient Descent(57/999): loss=23.870483530993518, w0=71.45503688531205, w1=17.119768196129364\n",
      "Gradient Descent(58/999): loss=23.701640077316462, w0=71.47342573647998, w1=17.08336763851796\n",
      "Gradient Descent(59/999): loss=23.53615660836757, w0=71.49163069913624, w1=17.04733108648267\n",
      "Gradient Descent(60/999): loss=23.373966260450757, w0=71.50965361216593, w1=17.011654899967734\n",
      "Gradient Descent(61/999): loss=23.215003500457478, w0=71.52749629606532, w1=16.976335475317946\n",
      "Gradient Descent(62/999): loss=23.059204099388076, w0=71.54516055312573, w1=16.941369244914657\n",
      "Gradient Descent(63/999): loss=22.906505106399955, w0=71.56264816761552, w1=16.9067526768154\n",
      "Gradient Descent(64/999): loss=22.7568448233723, w0=71.57996090596042, w1=16.872482274397136\n",
      "Gradient Descent(65/999): loss=22.61016277997689, w0=71.59710051692187, w1=16.838554576003055\n",
      "Gradient Descent(66/999): loss=22.466399709245046, w0=71.6140687317737, w1=16.804966154592915\n",
      "Gradient Descent(67/999): loss=22.325497523620783, w0=71.63086726447702, w1=16.771713617396877\n",
      "Gradient Descent(68/999): loss=22.187399291490433, w0=71.6474978118533, w1=16.7387936055728\n",
      "Gradient Descent(69/999): loss=22.052049214179476, w0=71.66396205375582, w1=16.70620279386696\n",
      "Gradient Descent(70/999): loss=21.919392603406997, w0=71.68026165323931, w1=16.673937890278182\n",
      "Gradient Descent(71/999): loss=21.78937585918892, w0=71.69639825672797, w1=16.64199563572529\n",
      "Gradient Descent(72/999): loss=21.661946448180753, w0=71.71237349418175, w1=16.61037280371793\n",
      "Gradient Descent(73/999): loss=21.53705288245167, w0=71.72818897926098, w1=16.579066200030642\n",
      "Gradient Descent(74/999): loss=21.414644698680593, w0=71.74384630948941, w1=16.548072662380225\n",
      "Gradient Descent(75/999): loss=21.29467243776656, w0=71.75934706641557, w1=16.517389060106314\n",
      "Gradient Descent(76/999): loss=21.177087624844713, w0=71.77469281577247, w1=16.48701229385514\n",
      "Gradient Descent(77/999): loss=21.06184274970001, w0=71.7898851076358, w1=16.45693929526648\n",
      "Gradient Descent(78/999): loss=20.94889124757068, w0=71.8049254765805, w1=16.427167026663707\n",
      "Gradient Descent(79/999): loss=20.838187480333726, w0=71.81981544183574, w1=16.39769248074696\n",
      "Gradient Descent(80/999): loss=20.72968671806479, w0=71.83455650743844, w1=16.36851268028938\n",
      "Gradient Descent(81/999): loss=20.62334512096501, w0=71.8491501623851, w1=16.33962467783638\n",
      "Gradient Descent(82/999): loss=20.519119721647513, w0=71.86359788078231, w1=16.311025555407905\n",
      "Gradient Descent(83/999): loss=20.416968407776423, w0=71.87790112199554, w1=16.282712424203716\n",
      "Gradient Descent(84/999): loss=20.316849905051377, w0=71.89206133079664, w1=16.254682424311568\n",
      "Gradient Descent(85/999): loss=20.21872376053055, w0=71.90607993750972, w1=16.226932724418344\n",
      "Gradient Descent(86/999): loss=20.122550326285705, w0=71.91995835815567, w1=16.19946052152405\n",
      "Gradient Descent(87/999): loss=20.028290743382325, w0=71.93369799459516, w1=16.1722630406587\n",
      "Gradient Descent(88/999): loss=19.935906926178724, w0=71.94730023467027, w1=16.145337534602003\n",
      "Gradient Descent(89/999): loss=19.84536154693747, w0=71.96076645234461, w1=16.118681283605873\n",
      "Gradient Descent(90/999): loss=19.75661802074312, w0=71.97409800784222, w1=16.092291595119704\n",
      "Gradient Descent(91/999): loss=19.669640490720038, w0=71.98729624778484, w1=16.0661658035184\n",
      "Gradient Descent(92/999): loss=19.584393813544423, w0=72.00036250532804, w1=16.040301269833105\n",
      "Gradient Descent(93/999): loss=19.5008435452446, w0=72.01329810029581, w1=16.014695381484664\n",
      "Gradient Descent(94/999): loss=19.418955927283935, w0=72.0261043393139, w1=15.989345552019708\n",
      "Gradient Descent(95/999): loss=19.338697872920694, w0=72.03878251594182, w1=15.964249220849402\n",
      "Gradient Descent(96/999): loss=19.260036953839275, w0=72.05133391080345, w1=15.939403852990798\n",
      "Gradient Descent(97/999): loss=19.182941387047585, w0=72.06375979171646, w1=15.91480693881078\n",
      "Gradient Descent(98/999): loss=19.10738002203504, w0=72.07606141382036, w1=15.890455993772564\n",
      "Gradient Descent(99/999): loss=19.03332232818625, w0=72.0882400197032, w1=15.866348558184729\n",
      "Gradient Descent(100/999): loss=18.960738382445047, w0=72.10029683952723, w1=15.842482196952773\n",
      "Gradient Descent(101/999): loss=18.88959885722409, w0=72.11223309115302, w1=15.818854499333135\n",
      "Gradient Descent(102/999): loss=18.819875008555027, w0=72.12404998026254, w1=15.795463078689695\n",
      "Gradient Descent(103/999): loss=18.751538664474484, w0=72.13574870048097, w1=15.772305572252687\n",
      "Gradient Descent(104/999): loss=18.68456221364114, w0=72.14733043349722, w1=15.74937964088005\n",
      "Gradient Descent(105/999): loss=18.618918594179384, w0=72.15879634918329, w1=15.726682968821141\n",
      "Gradient Descent(106/999): loss=18.554581282744927, w0=72.17014760571251, w1=15.70421326348282\n",
      "Gradient Descent(107/999): loss=18.491524283808005, w0=72.18138534967645, w1=15.681968255197884\n",
      "Gradient Descent(108/999): loss=18.429722119149925, w0=72.19251071620073, w1=15.659945696995795\n",
      "Gradient Descent(109/999): loss=18.369149817568548, w0=72.20352482905977, w1=15.638143364375727\n",
      "Gradient Descent(110/999): loss=18.30978290478864, w0=72.21442880079023, w1=15.61655905508186\n",
      "Gradient Descent(111/999): loss=18.251597393573046, w0=72.22522373280339, w1=15.595190588880932\n",
      "Gradient Descent(112/999): loss=18.194569774030644, w0=72.2359107154964, w1=15.574035807342014\n",
      "Gradient Descent(113/999): loss=18.13867700411714, w0=72.2464908283625, w1=15.553092573618484\n",
      "Gradient Descent(114/999): loss=18.083896500324904, w0=72.25696514009992, w1=15.53235877223219\n",
      "Gradient Descent(115/999): loss=18.030206128558152, w0=72.26733470871997, w1=15.511832308859757\n",
      "Gradient Descent(116/999): loss=17.97758419518955, w0=72.27760058165383, w1=15.491511110121051\n",
      "Gradient Descent(117/999): loss=17.92600943829498, w0=72.28776379585834, w1=15.471393123369731\n",
      "Gradient Descent(118/999): loss=17.875461019062616, w0=72.2978253779208, w1=15.451476316485925\n",
      "Gradient Descent(119/999): loss=17.825918513372986, w0=72.30778634416265, w1=15.431758677670956\n",
      "Gradient Descent(120/999): loss=17.777361903546563, w0=72.31764770074207, w1=15.412238215244138\n",
      "Gradient Descent(121/999): loss=17.729771570255693, w0=72.3274104437557, w1=15.392912957441586\n",
      "Gradient Descent(122/999): loss=17.68312828459732, w0=72.3370755593392, w1=15.37378095221706\n",
      "Gradient Descent(123/999): loss=17.637413200323532, w0=72.34664402376686, w1=15.35484026704478\n",
      "Gradient Descent(124/999): loss=17.592607846226798, w0=72.35611680355024, w1=15.336088988724223\n",
      "Gradient Descent(125/999): loss=17.54869411867659, w0=72.36549485553579, w1=15.317525223186871\n",
      "Gradient Descent(126/999): loss=17.505654274304632, w0=72.37477912700147, w1=15.299147095304892\n",
      "Gradient Descent(127/999): loss=17.46347092283568, w0=72.38397055575251, w1=15.280952748701734\n",
      "Gradient Descent(128/999): loss=17.42212702006095, w0=72.39307007021604, w1=15.262940345564608\n",
      "Gradient Descent(129/999): loss=17.381605860951446, w0=72.40207858953494, w1=15.245108066458853\n",
      "Gradient Descent(130/999): loss=17.34189107290821, w0=72.41099702366064, w1=15.227454110144155\n",
      "Gradient Descent(131/999): loss=17.302966609147045, w0=72.41982627344508, w1=15.209976693392603\n",
      "Gradient Descent(132/999): loss=17.264816742214727, w0=72.42856723073169, w1=15.192674050808568\n",
      "Gradient Descent(133/999): loss=17.227426057634354, w0=72.43722077844542, w1=15.175544434650373\n",
      "Gradient Descent(134/999): loss=17.190779447677134, w0=72.44578779068202, w1=15.15858611465376\n",
      "Gradient Descent(135/999): loss=17.15486210525807, w0=72.45426913279626, w1=15.141797377857113\n",
      "Gradient Descent(136/999): loss=17.119659517953135, w0=72.46266566148934, w1=15.125176528428433\n",
      "Gradient Descent(137/999): loss=17.085157462135573, w0=72.4709782248955, w1=15.10872188749404\n",
      "Gradient Descent(138/999): loss=17.051341997228782, w0=72.4792076626676, w1=15.09243179296899\n",
      "Gradient Descent(139/999): loss=17.018199460073628, w0=72.48735480606199, w1=15.07630459938919\n",
      "Gradient Descent(140/999): loss=16.98571645940786, w0=72.49542047802242, w1=15.060338677745188\n",
      "Gradient Descent(141/999): loss=16.953879870455346, w0=72.50340549326326, w1=15.044532415317626\n",
      "Gradient Descent(142/999): loss=16.922676829622983, w0=72.51131065835168, w1=15.02888421551434\n",
      "Gradient Descent(143/999): loss=16.892094729303196, w0=72.5191367717892, w1=15.013392497709088\n",
      "Gradient Descent(144/999): loss=16.862121212779773, w0=72.52688462409236, w1=14.998055697081888\n",
      "Gradient Descent(145/999): loss=16.832744169235163, w0=72.53455499787249, w1=14.98287226446096\n",
      "Gradient Descent(146/999): loss=16.803951728857086, w0=72.54214866791482, w1=14.967840666166241\n",
      "Gradient Descent(147/999): loss=16.775732258042535, w0=72.54966640125672, w1=14.95295938385447\n",
      "Gradient Descent(148/999): loss=16.748074354697202, w0=72.5571089572652, w1=14.938226914365815\n",
      "Gradient Descent(149/999): loss=16.720966843628428, w0=72.5644770877136, w1=14.923641769572047\n",
      "Gradient Descent(150/999): loss=16.694398772029928, w0=72.57177153685751, w1=14.909202476226216\n",
      "Gradient Descent(151/999): loss=16.668359405056243, w0=72.57899304150999, w1=14.894907575813845\n",
      "Gradient Descent(152/999): loss=16.642838221485324, w0=72.58614233111594, w1=14.880755624405596\n",
      "Gradient Descent(153/999): loss=16.617824909467473, w0=72.59322012782583, w1=14.86674519251143\n",
      "Gradient Descent(154/999): loss=16.593309362358777, w0=72.60022714656863, w1=14.852874864936206\n",
      "Gradient Descent(155/999): loss=16.569281674637537, w0=72.60716409512399, w1=14.839143240636734\n",
      "Gradient Descent(156/999): loss=16.545732137901958, w0=72.6140316741938, w1=14.825548932580256\n",
      "Gradient Descent(157/999): loss=16.522651236947418, w0=72.62083057747292, w1=14.812090567604344\n",
      "Gradient Descent(158/999): loss=16.500029645921863, w0=72.62756149171923, w1=14.79876678627819\n",
      "Gradient Descent(159/999): loss=16.477858224557725, w0=72.63422509682309, w1=14.785576242765298\n",
      "Gradient Descent(160/999): loss=16.456128014478736, w0=72.64082206587591, w1=14.772517604687536\n",
      "Gradient Descent(161/999): loss=16.434830235580314, w0=72.6473530652382, w1=14.759589552990551\n",
      "Gradient Descent(162/999): loss=16.41395628248197, w0=72.65381875460687, w1=14.746790781810537\n",
      "Gradient Descent(163/999): loss=16.393497721050284, w0=72.66021978708186, w1=14.734119998342322\n",
      "Gradient Descent(164/999): loss=16.37344628499109, w0=72.66655680923209, w1=14.721575922708789\n",
      "Gradient Descent(165/999): loss=16.35379387250947, w0=72.67283046116083, w1=14.70915728783159\n",
      "Gradient Descent(166/999): loss=16.334532543036232, w0=72.67904137657027, w1=14.696862839303165\n",
      "Gradient Descent(167/999): loss=16.315654514019517, w0=72.68519018282562, w1=14.684691335260023\n",
      "Gradient Descent(168/999): loss=16.297152157780232, w0=72.69127750101842, w1=14.672641546257314\n",
      "Gradient Descent(169/999): loss=16.27901799843011, w0=72.6973039460293, w1=14.660712255144631\n",
      "Gradient Descent(170/999): loss=16.26124470885105, w0=72.70327012659006, w1=14.648902256943074\n",
      "Gradient Descent(171/999): loss=16.24382510773462, w0=72.70917664534521, w1=14.637210358723534\n",
      "Gradient Descent(172/999): loss=16.226752156680405, w0=72.7150240989128, w1=14.625635379486189\n",
      "Gradient Descent(173/999): loss=16.21001895735217, w0=72.72081307794473, w1=14.614176150041217\n",
      "Gradient Descent(174/999): loss=16.193618748690568, w0=72.72654416718633, w1=14.602831512890695\n",
      "Gradient Descent(175/999): loss=16.177544904181328, w0=72.73221794553552, w1=14.59160032211168\n",
      "Gradient Descent(176/999): loss=16.161790929177826, w0=72.73783498610122, w1=14.580481443240453\n",
      "Gradient Descent(177/999): loss=16.146350458276892, w0=72.74339585626126, w1=14.569473753157938\n",
      "Gradient Descent(178/999): loss=16.131217252746886, w0=72.7489011177197, w1=14.55857613997625\n",
      "Gradient Descent(179/999): loss=16.116385198006927, w0=72.75435132656355, w1=14.547787502926377\n",
      "Gradient Descent(180/999): loss=16.101848301156295, w0=72.75974703331897, w1=14.537106752247004\n",
      "Gradient Descent(181/999): loss=16.087600688552985, w0=72.76508878300683, w1=14.526532809074425\n",
      "Gradient Descent(182/999): loss=16.07363660344049, w0=72.77037711519782, w1=14.516064605333572\n",
      "Gradient Descent(183/999): loss=16.059950403621727, w0=72.77561256406689, w1=14.505701083630127\n",
      "Gradient Descent(184/999): loss=16.046536559179362, w0=72.78079565844727, w1=14.495441197143716\n",
      "Gradient Descent(185/999): loss=16.033389650241396, w0=72.78592692188386, w1=14.485283909522169\n",
      "Gradient Descent(186/999): loss=16.020504364791297, w0=72.79100687268607, w1=14.475228194776838\n",
      "Gradient Descent(187/999): loss=16.007875496521656, w0=72.79603602398026, w1=14.46527303717896\n",
      "Gradient Descent(188/999): loss=15.995497942730578, w0=72.80101488376151, w1=14.455417431157061\n",
      "Gradient Descent(189/999): loss=15.983366702259946, w0=72.80594395494495, w1=14.445660381195381\n",
      "Gradient Descent(190/999): loss=15.971476873474677, w0=72.81082373541655, w1=14.436000901733317\n",
      "Gradient Descent(191/999): loss=15.959823652282235, w0=72.81565471808344, w1=14.426438017065875\n",
      "Gradient Descent(192/999): loss=15.948402330191527, w0=72.82043739092366, w1=14.416970761245107\n",
      "Gradient Descent(193/999): loss=15.937208292410418, w0=72.82517223703547, w1=14.407598177982546\n",
      "Gradient Descent(194/999): loss=15.926237015981155, w0=72.82985973468617, w1=14.398319320552611\n",
      "Gradient Descent(195/999): loss=15.915484067952837, w0=72.83450035736035, w1=14.389133251696975\n",
      "Gradient Descent(196/999): loss=15.904945103590281, w0=72.8390945738078, w1=14.380039043529896\n",
      "Gradient Descent(197/999): loss=15.894615864618542, w0=72.84364284809077, w1=14.371035777444488\n",
      "Gradient Descent(198/999): loss=15.88449217750234, w0=72.84814563963091, w1=14.362122544019934\n",
      "Gradient Descent(199/999): loss=15.87456995175975, w0=72.85260340325566, w1=14.353298442929626\n",
      "Gradient Descent(200/999): loss=15.864845178309432, w0=72.85701658924415, w1=14.34456258285022\n",
      "Gradient Descent(201/999): loss=15.855313927850782, w0=72.86138564337277, w1=14.335914081371607\n",
      "Gradient Descent(202/999): loss=15.84597234927625, w0=72.8657110069601, w1=14.327352064907782\n",
      "Gradient Descent(203/999): loss=15.836816668115357, w0=72.86999311691154, w1=14.318875668608595\n",
      "Gradient Descent(204/999): loss=15.827843185009568, w0=72.87423240576348, w1=14.310484036272399\n",
      "Gradient Descent(205/999): loss=15.819048274217586, w0=72.8784293017269, w1=14.302176320259566\n",
      "Gradient Descent(206/999): loss=15.810428382150361, w0=72.88258422873068, w1=14.293951681406861\n",
      "Gradient Descent(207/999): loss=15.801980025935276, w0=72.88669760646442, w1=14.285809288942684\n",
      "Gradient Descent(208/999): loss=15.793699792008871, w0=72.89076985042082, w1=14.277748320403147\n",
      "Gradient Descent(209/999): loss=15.785584334737601, w0=72.89480137193767, w1=14.269767961549006\n",
      "Gradient Descent(210/999): loss=15.777630375066025, w0=72.89879257823935, w1=14.261867406283406\n",
      "Gradient Descent(211/999): loss=15.769834699191913, w0=72.90274387247801, w1=14.254045856570462\n",
      "Gradient Descent(212/999): loss=15.762194157267697, w0=72.90665565377428, w1=14.246302522354648\n",
      "Gradient Descent(213/999): loss=15.754705662127776, w0=72.91052831725759, w1=14.238636621480993\n",
      "Gradient Descent(214/999): loss=15.747366188041141, w0=72.91436225410607, w1=14.231047379616074\n",
      "Gradient Descent(215/999): loss=15.740172769488826, w0=72.91815785158606, w1=14.223534030169803\n",
      "Gradient Descent(216/999): loss=15.733122499965704, w0=72.92191549309125, w1=14.216095814217995\n",
      "Gradient Descent(217/999): loss=15.726212530806093, w0=72.92563555818138, w1=14.208731980425705\n",
      "Gradient Descent(218/999): loss=15.719440070032757, w0=72.92931842262063, w1=14.201441784971339\n",
      "Gradient Descent(219/999): loss=15.71280238122881, w0=72.93296445841547, w1=14.194224491471516\n",
      "Gradient Descent(220/999): loss=15.70629678243206, w0=72.93657403385237, w1=14.187079370906691\n",
      "Gradient Descent(221/999): loss=15.699920645051368, w0=72.9401475135349, w1=14.180005701547515\n",
      "Gradient Descent(222/999): loss=15.69367139280455, w0=72.9436852584206, w1=14.173002768881931\n",
      "Gradient Descent(223/999): loss=15.687546500677444, w0=72.94718762585745, w1=14.166069865543003\n",
      "Gradient Descent(224/999): loss=15.68154349390367, w0=72.95065496961993, w1=14.159206291237464\n",
      "Gradient Descent(225/999): loss=15.67565994696469, w0=72.95408763994479, w1=14.15241135267498\n",
      "Gradient Descent(226/999): loss=15.669893482609794, w0=72.95748598356639, w1=14.14568436349812\n",
      "Gradient Descent(227/999): loss=15.664241770895565, w0=72.96085034375177, w1=14.139024644213029\n",
      "Gradient Descent(228/999): loss=15.658702528244453, w0=72.9641810603353, w1=14.13243152212079\n",
      "Gradient Descent(229/999): loss=15.653273516522091, w0=72.967478469753, w1=14.125904331249473\n",
      "Gradient Descent(230/999): loss=15.647952542133009, w0=72.97074290507652, w1=14.119442412286869\n",
      "Gradient Descent(231/999): loss=15.642737455134268, w0=72.97397469604681, w1=14.113045112513891\n",
      "Gradient Descent(232/999): loss=15.6376261483668, w0=72.9771741691074, w1=14.106711785738643\n",
      "Gradient Descent(233/999): loss=15.632616556604003, w0=72.98034164743738, w1=14.100441792231146\n",
      "Gradient Descent(234/999): loss=15.627706655717288, w0=72.98347745098407, w1=14.094234498658725\n",
      "Gradient Descent(235/999): loss=15.622894461858218, w0=72.98658189649528, w1=14.088089278022029\n",
      "Gradient Descent(236/999): loss=15.618178030656942, w0=72.98965529755138, w1=14.0820055095917\n",
      "Gradient Descent(237/999): loss=15.613555456436574, w0=72.99269796459691, w1=14.075982578845673\n",
      "Gradient Descent(238/999): loss=15.609024871443195, w0=72.995710204972, w1=14.070019877407107\n",
      "Gradient Descent(239/999): loss=15.604584445091179, w0=72.99869232294333, w1=14.064116802982927\n",
      "Gradient Descent(240/999): loss=15.60023238322357, w0=73.00164461973495, w1=14.058272759302987\n",
      "Gradient Descent(241/999): loss=15.595966927387126, w0=73.00456739355864, w1=14.052487156059847\n",
      "Gradient Descent(242/999): loss=15.591786354121828, w0=73.0074609396441, w1=14.04675940884914\n",
      "Gradient Descent(243/999): loss=15.58768897426451, w0=73.01032555026872, w1=14.041088939110539\n",
      "Gradient Descent(244/999): loss=15.583673132266348, w0=73.01316151478709, w1=14.035475174069324\n",
      "Gradient Descent(245/999): loss=15.579737205523957, w0=73.01596911966027, w1=14.029917546678522\n",
      "Gradient Descent(246/999): loss=15.575879603723733, w0=73.01874864848472, w1=14.024415495561627\n",
      "Gradient Descent(247/999): loss=15.572098768199334, w0=73.02150038202092, w1=14.0189684649559\n",
      "Gradient Descent(248/999): loss=15.568393171301874, w0=73.02422459822176, w1=14.013575904656232\n",
      "Gradient Descent(249/999): loss=15.564761315782674, w0=73.0269215722606, w1=14.00823726995956\n",
      "Gradient Descent(250/999): loss=15.561201734188298, w0=73.02959157655906, w1=14.002952021609854\n",
      "Gradient Descent(251/999): loss=15.557712988267655, w0=73.03223488081451, w1=13.997719625743645\n",
      "Gradient Descent(252/999): loss=15.554293668390837, w0=73.03485175202742, w1=13.9925395538361\n",
      "Gradient Descent(253/999): loss=15.550942392979563, w0=73.0374424545282, w1=13.98741128264763\n",
      "Gradient Descent(254/999): loss=15.547657807948976, w0=73.04000725000397, w1=13.982334294171043\n",
      "Gradient Descent(255/999): loss=15.544438586160494, w0=73.04254639752497, w1=13.977308075579224\n",
      "Gradient Descent(256/999): loss=15.541283426885606, w0=73.04506015357077, w1=13.972332119173322\n",
      "Gradient Descent(257/999): loss=15.53819105528029, w0=73.04754877205612, w1=13.967405922331478\n",
      "Gradient Descent(258/999): loss=15.535160221869917, w0=73.0500125043566, w1=13.962528987458054\n",
      "Gradient Descent(259/999): loss=15.532189702044413, w0=73.05245159933409, w1=13.957700821933363\n",
      "Gradient Descent(260/999): loss=15.529278295563435, w0=73.0548663033618, w1=13.95292093806392\n",
      "Gradient Descent(261/999): loss=15.526424826071423, w0=73.05725686034924, w1=13.948188853033171\n",
      "Gradient Descent(262/999): loss=15.52362814062231, w0=73.0596235117668, w1=13.94350408885273\n",
      "Gradient Descent(263/999): loss=15.52088710921363, w0=73.06196649667018, w1=13.938866172314093\n",
      "Gradient Descent(264/999): loss=15.518200624329982, w0=73.06428605172454, w1=13.934274634940842\n",
      "Gradient Descent(265/999): loss=15.515567600495519, w0=73.06658241122834, w1=13.929729012941323\n",
      "Gradient Descent(266/999): loss=15.512986973835368, w0=73.06885580713711, w1=13.925228847161799\n",
      "Gradient Descent(267/999): loss=15.510457701645741, w0=73.07110646908679, w1=13.920773683040071\n",
      "Gradient Descent(268/999): loss=15.507978761972703, w0=73.07333462441697, w1=13.91636307055956\n",
      "Gradient Descent(269/999): loss=15.505549153199148, w0=73.07554049819386, w1=13.911996564203855\n",
      "Gradient Descent(270/999): loss=15.503167893640187, w0=73.07772431323298, w1=13.907673722911708\n",
      "Gradient Descent(271/999): loss=15.500834021146453, w0=73.0798862901217, w1=13.903394110032481\n",
      "Gradient Descent(272/999): loss=15.498546592715345, w0=73.08202664724153, w1=13.899157293282046\n",
      "Gradient Descent(273/999): loss=15.496304684110015, w0=73.08414560079017, w1=13.894962844699116\n",
      "Gradient Descent(274/999): loss=15.49410738948593, w0=73.08624336480331, w1=13.890810340602014\n",
      "Gradient Descent(275/999): loss=15.491953821024866, w0=73.08832015117633, w1=13.886699361545885\n",
      "Gradient Descent(276/999): loss=15.489843108576176, w0=73.09037616968563, w1=13.882629492280316\n",
      "Gradient Descent(277/999): loss=15.487774399305213, w0=73.09241162800983, w1=13.878600321707403\n",
      "Gradient Descent(278/999): loss=15.485746857348746, w0=73.09442673175079, w1=13.87461144284022\n",
      "Gradient Descent(279/999): loss=15.483759663477208, w0=73.09642168445433, w1=13.870662452761708\n",
      "Gradient Descent(280/999): loss=15.481812014763717, w0=73.09839668763084, w1=13.866752952583981\n",
      "Gradient Descent(281/999): loss=15.479903124259625, w0=73.10035194077558, w1=13.862882547408033\n",
      "Gradient Descent(282/999): loss=15.478032220676562, w0=73.10228764138888, w1=13.859050846283843\n",
      "Gradient Descent(283/999): loss=15.476198548074803, w0=73.10420398499605, w1=13.855257462170895\n",
      "Gradient Descent(284/999): loss=15.474401365557819, w0=73.10610116516713, w1=13.851502011899077\n",
      "Gradient Descent(285/999): loss=15.472639946972926, w0=73.10797937353651, w1=13.847784116129978\n",
      "Gradient Descent(286/999): loss=15.47091358061787, w0=73.1098387998222, w1=13.844103399318568\n",
      "Gradient Descent(287/999): loss=15.46922156895328, w0=73.11167963184504, w1=13.840459489675272\n",
      "Gradient Descent(288/999): loss=15.467563228320813, w0=73.11350205554764, w1=13.83685201912841\n",
      "Gradient Descent(289/999): loss=15.465937888666932, w0=73.11530625501322, w1=13.833280623287015\n",
      "Gradient Descent(290/999): loss=15.464344893272166, w0=73.11709241248414, w1=13.829744941404035\n",
      "Gradient Descent(291/999): loss=15.462783598485752, w0=73.11886070838035, w1=13.826244616339885\n",
      "Gradient Descent(292/999): loss=15.46125337346559, w0=73.1206113213176, w1=13.822779294526377\n",
      "Gradient Descent(293/999): loss=15.459753599923332, w0=73.12234442812547, w1=13.819348625931005\n",
      "Gradient Descent(294/999): loss=15.458283671874565, w0=73.12406020386527, w1=13.815952264021584\n",
      "Gradient Descent(295/999): loss=15.456842995393966, w0=73.12575882184767, w1=13.812589865731258\n",
      "Gradient Descent(296/999): loss=15.45543098837533, w0=73.12744045365024, w1=13.809261091423837\n",
      "Gradient Descent(297/999): loss=15.454047080296366, w0=73.12910526913478, w1=13.80596560485949\n",
      "Gradient Descent(298/999): loss=15.452690711988177, w0=73.13075343646449, w1=13.802703073160785\n",
      "Gradient Descent(299/999): loss=15.451361335409317, w0=73.1323851221209, w1=13.799473166779068\n",
      "Gradient Descent(300/999): loss=15.450058413424374, w0=73.13400049092074, w1=13.796275559461167\n",
      "Gradient Descent(301/999): loss=15.448781419586934, w0=73.13559970603258, w1=13.793109928216445\n",
      "Gradient Descent(302/999): loss=15.447529837926862, w0=73.13718292899331, w1=13.789975953284172\n",
      "Gradient Descent(303/999): loss=15.446303162741819, w0=73.13875031972444, w1=13.78687331810122\n",
      "Gradient Descent(304/999): loss=15.445100898392962, w0=73.14030203654825, w1=13.783801709270099\n",
      "Gradient Descent(305/999): loss=15.443922559104648, w0=73.14183823620382, w1=13.78076081652729\n",
      "Gradient Descent(306/999): loss=15.442767668768166, w0=73.14335907386284, w1=13.777750332711907\n",
      "Gradient Descent(307/999): loss=15.441635760749387, w0=73.14486470314526, w1=13.774769953734678\n",
      "Gradient Descent(308/999): loss=15.440526377700179, w0=73.14635527613486, w1=13.771819378547221\n",
      "Gradient Descent(309/999): loss=15.43943907137365, w0=73.14783094339455, w1=13.76889830911164\n",
      "Gradient Descent(310/999): loss=15.438373402443021, w0=73.14929185398167, w1=13.766006450370414\n",
      "Gradient Descent(311/999): loss=15.43732894032411, w0=73.1507381554629, w1=13.7631435102166\n",
      "Gradient Descent(312/999): loss=15.436305263001364, w0=73.15216999392932, w1=13.760309199464325\n",
      "Gradient Descent(313/999): loss=15.435301956857344, w0=73.15358751401108, w1=13.757503231819573\n",
      "Gradient Descent(314/999): loss=15.43431861650559, w0=73.15499085889202, w1=13.754725323851268\n",
      "Gradient Descent(315/999): loss=15.43335484462683, w0=73.15638017032416, w1=13.751975194962647\n",
      "Gradient Descent(316/999): loss=15.432410251808461, w0=73.15775558864196, w1=13.74925256736291\n",
      "Gradient Descent(317/999): loss=15.431484456387176, w0=73.1591172527766, w1=13.746557166039173\n",
      "Gradient Descent(318/999): loss=15.430577084294777, w0=73.16046530026988, w1=13.743888718728671\n",
      "Gradient Descent(319/999): loss=15.42968776890702, w0=73.16179986728822, w1=13.741246955891276\n",
      "Gradient Descent(320/999): loss=15.428816150895473, w0=73.16312108863639, w1=13.738631610682253\n",
      "Gradient Descent(321/999): loss=15.42796187808236, w0=73.16442909777108, w1=13.73604241892532\n",
      "Gradient Descent(322/999): loss=15.427124605298225, w0=73.16572402681442, w1=13.733479119085958\n",
      "Gradient Descent(323/999): loss=15.426303994242497, w0=73.16700600656732, w1=13.73094145224499\n",
      "Gradient Descent(324/999): loss=15.425499713346776, w0=73.1682751665227, w1=13.72842916207243\n",
      "Gradient Descent(325/999): loss=15.42471143764088, w0=73.16953163487852, w1=13.725941994801596\n",
      "Gradient Descent(326/999): loss=15.423938848621532, w0=73.17077553855079, w1=13.723479699203471\n",
      "Gradient Descent(327/999): loss=15.42318163412367, w0=73.17200700318632, w1=13.721042026561328\n",
      "Gradient Descent(328/999): loss=15.422439488194316, w0=73.1732261531755, w1=13.718628730645605\n",
      "Gradient Descent(329/999): loss=15.421712110968953, w0=73.1744331116648, w1=13.716239567689039\n",
      "Gradient Descent(330/999): loss=15.420999208550379, w0=73.1756280005692, w1=13.71387429636204\n",
      "Gradient Descent(331/999): loss=15.420300492889929, w0=73.17681094058456, w1=13.711532677748309\n",
      "Gradient Descent(332/999): loss=15.419615681671127, w0=73.17798205119976, w1=13.709214475320717\n",
      "Gradient Descent(333/999): loss=15.418944498195575, w0=73.17914145070881, w1=13.7069194549174\n",
      "Gradient Descent(334/999): loss=15.41828667127119, w0=73.18028925622278, w1=13.704647384718116\n",
      "Gradient Descent(335/999): loss=15.417641935102598, w0=73.1814255836816, w1=13.702398035220826\n",
      "Gradient Descent(336/999): loss=15.417010029183762, w0=73.18255054786584, w1=13.700171179218508\n",
      "Gradient Descent(337/999): loss=15.416390698192709, w0=73.18366426240824, w1=13.697966591776213\n",
      "Gradient Descent(338/999): loss=15.415783691888379, w0=73.1847668398052, w1=13.695784050208342\n",
      "Gradient Descent(339/999): loss=15.415188765009503, w0=73.18585839142821, w1=13.693623334056149\n",
      "Gradient Descent(340/999): loss=15.414605677175523, w0=73.18693902753498, w1=13.691484225065478\n",
      "Gradient Descent(341/999): loss=15.414034192789433, w0=73.18800885728068, w1=13.689366507164713\n",
      "Gradient Descent(342/999): loss=15.41347408094263, w0=73.18906798872892, w1=13.687269966442956\n",
      "Gradient Descent(343/999): loss=15.412925115321576, w0=73.19011652886269, w1=13.685194391128418\n",
      "Gradient Descent(344/999): loss=15.412387074116381, w0=73.19115458359511, w1=13.683139571567024\n",
      "Gradient Descent(345/999): loss=15.411859739931172, w0=73.1921822577802, w1=13.681105300201244\n",
      "Gradient Descent(346/999): loss=15.411342899696246, w0=73.19319965522345, w1=13.679091371549122\n",
      "Gradient Descent(347/999): loss=15.410836344581996, w0=73.19420687869227, w1=13.67709758218352\n",
      "Gradient Descent(348/999): loss=15.410339869914518, w0=73.1952040299264, w1=13.675123730711576\n",
      "Gradient Descent(349/999): loss=15.409853275092924, w0=73.19619120964819, w1=13.67316961775435\n",
      "Gradient Descent(350/999): loss=15.409376363508281, w0=73.19716851757276, w1=13.671235045926698\n",
      "Gradient Descent(351/999): loss=15.408908942464171, w0=73.19813605241809, w1=13.669319819817321\n",
      "Gradient Descent(352/999): loss=15.408450823098837, w0=73.19909391191496, w1=13.667423745969039\n",
      "Gradient Descent(353/999): loss=15.408001820308876, w0=73.20004219281687, w1=13.66554663285924\n",
      "Gradient Descent(354/999): loss=15.407561752674434, w0=73.20098099090976, w1=13.663688290880538\n",
      "Gradient Descent(355/999): loss=15.407130442385917, w0=73.2019104010217, w1=13.661848532321622\n",
      "Gradient Descent(356/999): loss=15.406707715172143, w0=73.20283051703254, w1=13.660027171348297\n",
      "Gradient Descent(357/999): loss=15.406293400229924, w0=73.20374143188326, w1=13.658224023984705\n",
      "Gradient Descent(358/999): loss=15.405887330155053, w0=73.20464323758547, w1=13.656438908094747\n",
      "Gradient Descent(359/999): loss=15.405489340874672, w0=73.20553602523067, w1=13.65467164336369\n",
      "Gradient Descent(360/999): loss=15.405099271580973, w0=73.20641988499942, w1=13.652922051279944\n",
      "Gradient Descent(361/999): loss=15.404716964666216, w0=73.20729490617047, w1=13.651189955117035\n",
      "Gradient Descent(362/999): loss=15.404342265659064, w0=73.20816117712982, w1=13.649475179915754\n",
      "Gradient Descent(363/999): loss=15.403975023162156, w0=73.20901878537958, w1=13.647777552466486\n",
      "Gradient Descent(364/999): loss=15.403615088790929, w0=73.20986781754684, w1=13.646096901291711\n",
      "Gradient Descent(365/999): loss=15.403262317113695, w0=73.21070835939241, w1=13.644433056628685\n",
      "Gradient Descent(366/999): loss=15.40291656559284, w0=73.21154049581953, w1=13.642785850412288\n",
      "Gradient Descent(367/999): loss=15.402577694527245, w0=73.21236431088239, w1=13.641155116258055\n",
      "Gradient Descent(368/999): loss=15.40224556699586, w0=73.21317988779462, w1=13.639540689445365\n",
      "Gradient Descent(369/999): loss=15.401920048802346, w0=73.21398730893773, w1=13.637942406900802\n",
      "Gradient Descent(370/999): loss=15.401601008420887, w0=73.2147866558694, w1=13.636360107181684\n",
      "Gradient Descent(371/999): loss=15.401288316943013, w0=73.21557800933176, w1=13.634793630459757\n",
      "Gradient Descent(372/999): loss=15.400981848025552, w0=73.2163614492595, w1=13.63324281850505\n",
      "Gradient Descent(373/999): loss=15.400681477839552, w0=73.21713705478795, w1=13.63170751466989\n",
      "Gradient Descent(374/999): loss=15.400387085020249, w0=73.21790490426113, w1=13.630187563873081\n",
      "Gradient Descent(375/999): loss=15.40009855061805, w0=73.21866507523957, w1=13.628682812584241\n",
      "Gradient Descent(376/999): loss=15.399815758050455, w0=73.21941764450823, w1=13.627193108808289\n",
      "Gradient Descent(377/999): loss=15.399538593054958, w0=73.2201626880842, w1=13.625718302070096\n",
      "Gradient Descent(378/999): loss=15.39926694364287, w0=73.22090028122442, w1=13.624258243399286\n",
      "Gradient Descent(379/999): loss=15.39900070005408, w0=73.22163049843323, w1=13.622812785315183\n",
      "Gradient Descent(380/999): loss=15.39873975471271, w0=73.22235341346995, w1=13.621381781811921\n",
      "Gradient Descent(381/999): loss=15.398484002183627, w0=73.2230690993563, w1=13.619965088343692\n",
      "Gradient Descent(382/999): loss=15.398233339129881, w0=73.22377762838379, w1=13.618562561810146\n",
      "Gradient Descent(383/999): loss=15.397987664270902, w0=73.224479072121, w1=13.617174060541934\n",
      "Gradient Descent(384/999): loss=15.397746878341614, w0=73.22517350142084, w1=13.615799444286406\n",
      "Gradient Descent(385/999): loss=15.397510884052323, w0=73.22586098642769, w1=13.614438574193432\n",
      "Gradient Descent(386/999): loss=15.397279586049388, w0=73.22654159658447, w1=13.613091312801389\n",
      "Gradient Descent(387/999): loss=15.397052890876706, w0=73.22721540063968, w1=13.611757524023266\n",
      "Gradient Descent(388/999): loss=15.396830706937966, w0=73.22788246665434, w1=13.610437073132925\n",
      "Gradient Descent(389/999): loss=15.396612944459607, w0=73.22854286200885, w1=13.609129826751486\n",
      "Gradient Descent(390/999): loss=15.396399515454565, w0=73.22919665340982, w1=13.607835652833861\n",
      "Gradient Descent(391/999): loss=15.396190333686722, w0=73.22984390689678, w1=13.606554420655414\n",
      "Gradient Descent(392/999): loss=15.395985314636063, w0=73.23048468784886, w1=13.60528600079875\n",
      "Gradient Descent(393/999): loss=15.395784375464512, w0=73.23111906099142, w1=13.604030265140654\n",
      "Gradient Descent(394/999): loss=15.39558743498247, w0=73.23174709040255, w1=13.602787086839138\n",
      "Gradient Descent(395/999): loss=15.395394413616025, w0=73.23236883951958, w1=13.601556340320636\n",
      "Gradient Descent(396/999): loss=15.39520523337477, w0=73.23298437114543, w1=13.60033790126732\n",
      "Gradient Descent(397/999): loss=15.39501981782032, w0=73.23359374745503, w1=13.599131646604537\n",
      "Gradient Descent(398/999): loss=15.394838092035398, w0=73.23419703000154, w1=13.597937454488383\n",
      "Gradient Descent(399/999): loss=15.394659982593602, w0=73.23479427972258, w1=13.59675520429339\n",
      "Gradient Descent(400/999): loss=15.39448541752969, w0=73.2353855569464, w1=13.595584776600345\n",
      "Gradient Descent(401/999): loss=15.394314326310553, w0=73.23597092139798, w1=13.594426053184232\n",
      "Gradient Descent(402/999): loss=15.394146639806682, w0=73.23655043220505, w1=13.59327891700228\n",
      "Gradient Descent(403/999): loss=15.393982290264233, w0=73.23712414790405, w1=13.592143252182147\n",
      "Gradient Descent(404/999): loss=15.393821211277682, w0=73.23769212644606, w1=13.591018944010216\n",
      "Gradient Descent(405/999): loss=15.393663337762959, w0=73.23825442520265, w1=13.589905878920003\n",
      "Gradient Descent(406/999): loss=15.393508605931181, w0=73.23881110097167, w1=13.588803944480693\n",
      "Gradient Descent(407/999): loss=15.393356953262858, w0=73.23936220998301, w1=13.587713029385776\n",
      "Gradient Descent(408/999): loss=15.39320831848263, w0=73.23990780790423, w1=13.58663302344181\n",
      "Gradient Descent(409/999): loss=15.393062641534533, w0=73.24044794984624, w1=13.585563817557281\n",
      "Gradient Descent(410/999): loss=15.3929198635577, w0=73.24098269036884, w1=13.584505303731598\n",
      "Gradient Descent(411/999): loss=15.392779926862605, w0=73.2415120834862, w1=13.583457375044173\n",
      "Gradient Descent(412/999): loss=15.392642774907744, w0=73.2420361826724, w1=13.582419925643622\n",
      "Gradient Descent(413/999): loss=15.392508352276788, w0=73.24255504086672, w1=13.581392850737076\n",
      "Gradient Descent(414/999): loss=15.392376604656182, w0=73.24306871047911, w1=13.580376046579596\n",
      "Gradient Descent(415/999): loss=15.39224747881323, w0=73.24357724339536, w1=13.579369410463691\n",
      "Gradient Descent(416/999): loss=15.392120922574552, w0=73.24408069098246, w1=13.578372840708944\n",
      "Gradient Descent(417/999): loss=15.391996884805025, w0=73.24457910409369, w1=13.577386236651746\n",
      "Gradient Descent(418/999): loss=15.39187531538711, w0=73.24507253307381, w1=13.576409498635119\n",
      "Gradient Descent(419/999): loss=15.391756165200611, w0=73.24556102776413, w1=13.575442527998659\n",
      "Gradient Descent(420/999): loss=15.391639386102822, w0=73.24604463750754, w1=13.574485227068562\n",
      "Gradient Descent(421/999): loss=15.391524930909082, w0=73.24652341115352, w1=13.573537499147767\n",
      "Gradient Descent(422/999): loss=15.391412753373697, w0=73.24699739706304, w1=13.57259924850618\n",
      "Gradient Descent(423/999): loss=15.391302808171263, w0=73.24746664311346, w1=13.571670380371009\n",
      "Gradient Descent(424/999): loss=15.39119505087836, w0=73.24793119670338, w1=13.570750800917189\n",
      "Gradient Descent(425/999): loss=15.391089437955586, w0=73.24839110475739, w1=13.569840417257907\n",
      "Gradient Descent(426/999): loss=15.390985926729977, w0=73.24884641373086, w1=13.568939137435219\n",
      "Gradient Descent(427/999): loss=15.390884475377755, w0=73.24929716961461, w1=13.568046870410758\n",
      "Gradient Descent(428/999): loss=15.390785042907444, w0=73.24974341793951, w1=13.567163526056541\n",
      "Gradient Descent(429/999): loss=15.390687589143289, w0=73.25018520378117, w1=13.566289015145866\n",
      "Gradient Descent(430/999): loss=15.390592074709042, w0=73.25062257176441, w1=13.565423249344297\n",
      "Gradient Descent(431/999): loss=15.390498461012037, w0=73.25105556606782, w1=13.564566141200745\n",
      "Gradient Descent(432/999): loss=15.390406710227605, w0=73.25148423042819, w1=13.563717604138628\n",
      "Gradient Descent(433/999): loss=15.39031678528378, w0=73.25190860814496, w1=13.562877552447132\n",
      "Gradient Descent(434/999): loss=15.390228649846337, w0=73.25232874208456, w1=13.562045901272551\n",
      "Gradient Descent(435/999): loss=15.3901422683041, w0=73.25274467468476, w1=13.561222566609716\n",
      "Gradient Descent(436/999): loss=15.390057605754555, w0=73.25315644795897, w1=13.56040746529351\n",
      "Gradient Descent(437/999): loss=15.389974627989742, w0=73.25356410350044, w1=13.559600514990466\n",
      "Gradient Descent(438/999): loss=15.389893301482452, w0=73.25396768248649, w1=13.558801634190452\n",
      "Gradient Descent(439/999): loss=15.389813593372656, w0=73.25436722568267, w1=13.558010742198437\n",
      "Gradient Descent(440/999): loss=15.389735471454244, w0=73.2547627734469, w1=13.557227759126343\n",
      "Gradient Descent(441/999): loss=15.389658904162012, w0=73.25515436573347, w1=13.55645260588497\n",
      "Gradient Descent(442/999): loss=15.389583860558893, w0=73.25554204209719, w1=13.555685204176012\n",
      "Gradient Descent(443/999): loss=15.389510310323475, w0=73.25592584169728, w1=13.554925476484142\n",
      "Gradient Descent(444/999): loss=15.389438223737743, w0=73.25630580330136, w1=13.554173346069192\n",
      "Gradient Descent(445/999): loss=15.389367571675066, w0=73.2566819652894, w1=13.55342873695839\n",
      "Gradient Descent(446/999): loss=15.389298325588438, w0=73.25705436565757, w1=13.552691573938697\n",
      "Gradient Descent(447/999): loss=15.389230457498934, w0=73.25742304202204, w1=13.551961782549201\n",
      "Gradient Descent(448/999): loss=15.38916393998441, w0=73.25778803162287, w1=13.5512392890736\n",
      "Gradient Descent(449/999): loss=15.389098746168424, w0=73.25814937132769, w1=13.550524020532754\n",
      "Gradient Descent(450/999): loss=15.38903484970938, w0=73.25850709763546, w1=13.549815904677317\n",
      "Gradient Descent(451/999): loss=15.38897222478987, w0=73.25886124668015, w1=13.549114869980434\n",
      "Gradient Descent(452/999): loss=15.388910846106254, w0=73.25921185423441, w1=13.54842084563052\n",
      "Gradient Descent(453/999): loss=15.388850688858444, w0=73.25955895571312, w1=13.547733761524105\n",
      "Gradient Descent(454/999): loss=15.388791728739868, w0=73.25990258617703, w1=13.547053548258754\n",
      "Gradient Descent(455/999): loss=15.388733941927649, w0=73.26024278033631, w1=13.546380137126057\n",
      "Gradient Descent(456/999): loss=15.388677305072994, w0=73.26057957255401, w1=13.545713460104688\n",
      "Gradient Descent(457/999): loss=15.388621795291744, w0=73.26091299684951, w1=13.545053449853532\n",
      "Gradient Descent(458/999): loss=15.388567390155146, w0=73.26124308690207, w1=13.544400039704886\n",
      "Gradient Descent(459/999): loss=15.388514067680761, w0=73.2615698760541, w1=13.543753163657728\n",
      "Gradient Descent(460/999): loss=15.38846180632362, w0=73.26189339731461, w1=13.543112756371041\n",
      "Gradient Descent(461/999): loss=15.388410584967485, w0=73.26221368336252, w1=13.542478753157221\n",
      "Gradient Descent(462/999): loss=15.38836038291634, w0=73.26253076654994, w1=13.54185108997554\n",
      "Gradient Descent(463/999): loss=15.388311179886008, w0=73.2628446789055, w1=13.541229703425675\n",
      "Gradient Descent(464/999): loss=15.38826295599598, w0=73.2631554521375, w1=13.540614530741308\n",
      "Gradient Descent(465/999): loss=15.388215691761364, w0=73.26346311763717, w1=13.540005509783786\n",
      "Gradient Descent(466/999): loss=15.388169368085022, w0=73.26376770648186, w1=13.539402579035839\n",
      "Gradient Descent(467/999): loss=15.388123966249836, w0=73.2640692494381, w1=13.53880567759537\n",
      "Gradient Descent(468/999): loss=15.388079467911165, w0=73.26436777696476, w1=13.538214745169308\n",
      "Gradient Descent(469/999): loss=15.38803585508944, w0=73.26466331921617, w1=13.537629722067505\n",
      "Gradient Descent(470/999): loss=15.387993110162867, w0=73.26495590604506, w1=13.53705054919672\n",
      "Gradient Descent(471/999): loss=15.38795121586033, w0=73.26524556700566, w1=13.536477168054644\n",
      "Gradient Descent(472/999): loss=15.387910155254414, w0=73.26553233135665, w1=13.535909520723989\n",
      "Gradient Descent(473/999): loss=15.387869911754557, w0=73.26581622806414, w1=13.53534754986664\n",
      "Gradient Descent(474/999): loss=15.387830469100345, w0=73.26609728580455, w1=13.534791198717864\n",
      "Gradient Descent(475/999): loss=15.387791811354953, w0=73.26637553296756, w1=13.534240411080576\n",
      "Gradient Descent(476/999): loss=15.387753922898694, w0=73.26665099765893, w1=13.53369513131966\n",
      "Gradient Descent(477/999): loss=15.387716788422718, w0=73.26692370770338, w1=13.533155304356354\n",
      "Gradient Descent(478/999): loss=15.38768039292281, w0=73.2671936906474, w1=13.532620875662682\n",
      "Gradient Descent(479/999): loss=15.38764472169335, w0=73.26746097376198, w1=13.532091791255946\n",
      "Gradient Descent(480/999): loss=15.387609760321357, w0=73.26772558404542, w1=13.531567997693276\n",
      "Gradient Descent(481/999): loss=15.387575494680668, w0=73.26798754822602, w1=13.531049442066234\n",
      "Gradient Descent(482/999): loss=15.38754191092623, w0=73.26824689276481, w1=13.530536071995462\n",
      "Gradient Descent(483/999): loss=15.3875089954885, w0=73.26850364385821, w1=13.530027835625397\n",
      "Gradient Descent(484/999): loss=15.387476735067985, w0=73.26875782744068, w1=13.529524681619034\n",
      "Gradient Descent(485/999): loss=15.387445116629836, w0=73.26900946918732, w1=13.529026559152733\n",
      "Gradient Descent(486/999): loss=15.387414127398609, w0=73.2692585945165, w1=13.528533417911095\n",
      "Gradient Descent(487/999): loss=15.387383754853081, w0=73.2695052285924, w1=13.528045208081876\n",
      "Gradient Descent(488/999): loss=15.387353986721209, w0=73.26974939632753, w1=13.527561880350948\n",
      "Gradient Descent(489/999): loss=15.387324810975162, w0=73.2699911223853, w1=13.52708338589733\n",
      "Gradient Descent(490/999): loss=15.38729621582646, w0=73.27023043118251, w1=13.526609676388247\n",
      "Gradient Descent(491/999): loss=15.38726818972122, w0=73.27046734689173, w1=13.526140703974255\n",
      "Gradient Descent(492/999): loss=15.387240721335475, w0=73.27070189344387, w1=13.525676421284402\n",
      "Gradient Descent(493/999): loss=15.387213799570603, w0=73.27093409453049, w1=13.525216781421449\n",
      "Gradient Descent(494/999): loss=15.38718741354885, w0=73.27116397360624, w1=13.524761737957125\n",
      "Gradient Descent(495/999): loss=15.387161552608934, w0=73.27139155389122, w1=13.524311244927445\n",
      "Gradient Descent(496/999): loss=15.38713620630172, w0=73.27161685837336, w1=13.52386525682806\n",
      "Gradient Descent(497/999): loss=15.387111364386021, w0=73.27183990981068, w1=13.52342372860967\n",
      "Gradient Descent(498/999): loss=15.387087016824447, w0=73.27206073073363, w1=13.522986615673464\n",
      "Gradient Descent(499/999): loss=15.387063153779344, w0=73.27227934344734, w1=13.52255387386662\n",
      "Gradient Descent(500/999): loss=15.387039765608844, w0=73.27249577003391, w1=13.522125459477845\n",
      "Gradient Descent(501/999): loss=15.387016842862929, w0=73.27271003235462, w1=13.521701329232958\n",
      "Gradient Descent(502/999): loss=15.386994376279665, w0=73.27292215205213, w1=13.521281440290519\n",
      "Gradient Descent(503/999): loss=15.386972356781405, w0=73.27313215055267, w1=13.520865750237505\n",
      "Gradient Descent(504/999): loss=15.386950775471158, w0=73.2733400490682, w1=13.52045421708502\n",
      "Gradient Descent(505/999): loss=15.386929623628987, w0=73.27354586859856, w1=13.52004679926406\n",
      "Gradient Descent(506/999): loss=15.386908892708476, w0=73.27374962993363, w1=13.51964345562131\n",
      "Gradient Descent(507/999): loss=15.386888574333282, w0=73.27395135365535, w1=13.519244145414987\n",
      "Gradient Descent(508/999): loss=15.386868660293752, w0=73.27415106013984, w1=13.518848828310729\n",
      "Gradient Descent(509/999): loss=15.386849142543614, w0=73.2743487695595, w1=13.518457464377512\n",
      "Gradient Descent(510/999): loss=15.386830013196702, w0=73.27454450188495, w1=13.518070014083628\n",
      "Gradient Descent(511/999): loss=15.386811264523791, w0=73.27473827688715, w1=13.517686438292683\n",
      "Gradient Descent(512/999): loss=15.386792888949474, w0=73.27493011413932, w1=13.517306698259647\n",
      "Gradient Descent(513/999): loss=15.386774879049085, w0=73.27512003301898, w1=13.516930755626941\n",
      "Gradient Descent(514/999): loss=15.386757227545711, w0=73.27530805270985, w1=13.516558572420562\n",
      "Gradient Descent(515/999): loss=15.386739927307257, w0=73.2754941922038, w1=13.516190111046248\n",
      "Gradient Descent(516/999): loss=15.386722971343548, w0=73.27567847030281, w1=13.515825334285676\n",
      "Gradient Descent(517/999): loss=15.386706352803518, w0=73.27586090562083, w1=13.51546420529271\n",
      "Gradient Descent(518/999): loss=15.386690064972429, w0=73.27604151658568, w1=13.515106687589673\n",
      "Gradient Descent(519/999): loss=15.386674101269186, w0=73.27622032144087, w1=13.514752745063667\n",
      "Gradient Descent(520/999): loss=15.386658455243632, w0=73.27639733824752, w1=13.51440234196292\n",
      "Gradient Descent(521/999): loss=15.386643120573988, w0=73.2765725848861, w1=13.514055442893183\n",
      "Gradient Descent(522/999): loss=15.386628091064273, w0=73.27674607905828, w1=13.51371201281414\n",
      "Gradient Descent(523/999): loss=15.386613360641798, w0=73.27691783828875, w1=13.51337201703589\n",
      "Gradient Descent(524/999): loss=15.386598923354732, w0=73.27708787992692, w1=13.513035421215422\n",
      "Gradient Descent(525/999): loss=15.386584773369679, w0=73.2772562211487, w1=13.512702191353158\n",
      "Gradient Descent(526/999): loss=15.386570904969325, w0=73.27742287895826, w1=13.512372293789516\n",
      "Gradient Descent(527/999): loss=15.386557312550142, w0=73.27758787018973, w1=13.512045695201511\n",
      "Gradient Descent(528/999): loss=15.386543990620098, w0=73.27775121150889, w1=13.511722362599386\n",
      "Gradient Descent(529/999): loss=15.386530933796466, w0=73.27791291941485, w1=13.511402263323282\n",
      "Gradient Descent(530/999): loss=15.38651813680362, w0=73.27807301024176, w1=13.51108536503994\n",
      "Gradient Descent(531/999): loss=15.386505594470934, w0=73.27823150016039, w1=13.510771635739431\n",
      "Gradient Descent(532/999): loss=15.386493301730667, w0=73.27838840517984, w1=13.510461043731928\n",
      "Gradient Descent(533/999): loss=15.38648125361593, w0=73.2785437411491, w1=13.510153557644498\n",
      "Gradient Descent(534/999): loss=15.386469445258678, w0=73.27869752375865, w1=13.509849146417944\n",
      "Gradient Descent(535/999): loss=15.386457871887737, w0=73.27884976854212, w1=13.509547779303654\n",
      "Gradient Descent(536/999): loss=15.386446528826875, w0=73.27900049087775, w1=13.509249425860508\n",
      "Gradient Descent(537/999): loss=15.386435411492927, w0=73.27914970599002, w1=13.508954055951794\n",
      "Gradient Descent(538/999): loss=15.386424515393923, w0=73.27929742895117, w1=13.508661639742167\n",
      "Gradient Descent(539/999): loss=15.386413836127288, w0=73.27944367468271, w1=13.508372147694635\n",
      "Gradient Descent(540/999): loss=15.38640336937806, w0=73.27958845795693, w1=13.508085550567579\n",
      "Gradient Descent(541/999): loss=15.386393110917142, w0=73.27973179339841, w1=13.507801819411792\n",
      "Gradient Descent(542/999): loss=15.386383056599596, w0=73.27987369548548, w1=13.507520925567565\n",
      "Gradient Descent(543/999): loss=15.386373202362968, w0=73.28001417855168, w1=13.50724284066178\n",
      "Gradient Descent(544/999): loss=15.386363544225652, w0=73.28015325678722, w1=13.506967536605053\n",
      "Gradient Descent(545/999): loss=15.386354078285265, w0=73.28029094424039, w1=13.506694985588894\n",
      "Gradient Descent(546/999): loss=15.386344800717092, w0=73.28042725481905, w1=13.506425160082895\n",
      "Gradient Descent(547/999): loss=15.38633570777253, w0=73.2805622022919, w1=13.506158032831957\n",
      "Gradient Descent(548/999): loss=15.38632679577756, w0=73.28069580029003, w1=13.505893576853527\n",
      "Gradient Descent(549/999): loss=15.386318061131291, w0=73.28082806230819, w1=13.505631765434883\n",
      "Gradient Descent(550/999): loss=15.386309500304485, w0=73.28095900170617, w1=13.505372572130424\n",
      "Gradient Descent(551/999): loss=15.386301109838131, w0=73.28108863171016, w1=13.505115970759011\n",
      "Gradient Descent(552/999): loss=15.386292886342057, w0=73.28121696541412, w1=13.504861935401312\n",
      "Gradient Descent(553/999): loss=15.386284826493554, w0=73.28134401578103, w1=13.504610440397188\n",
      "Gradient Descent(554/999): loss=15.386276927036036, w0=73.28146979564427, w1=13.504361460343107\n",
      "Gradient Descent(555/999): loss=15.386269184777726, w0=73.28159431770888, w1=13.504114970089567\n",
      "Gradient Descent(556/999): loss=15.386261596590357, w0=73.28171759455284, w1=13.503870944738562\n",
      "Gradient Descent(557/999): loss=15.386254159407912, w0=73.28183963862837, w1=13.503629359641067\n",
      "Gradient Descent(558/999): loss=15.386246870225397, w0=73.28196046226314, w1=13.503390190394548\n",
      "Gradient Descent(559/999): loss=15.386239726097617, w0=73.28208007766156, w1=13.503153412840494\n",
      "Gradient Descent(560/999): loss=15.38623272413798, w0=73.28219849690599, w1=13.50291900306198\n",
      "Gradient Descent(561/999): loss=15.38622586151734, w0=73.28231573195798, w1=13.50268693738125\n",
      "Gradient Descent(562/999): loss=15.38621913546285, w0=73.28243179465944, w1=13.502457192357328\n",
      "Gradient Descent(563/999): loss=15.386212543256846, w0=73.2825466967339, w1=13.502229744783644\n",
      "Gradient Descent(564/999): loss=15.386206082235736, w0=73.28266044978761, w1=13.5020045716857\n",
      "Gradient Descent(565/999): loss=15.386199749788954, w0=73.28277306531079, w1=13.501781650318733\n",
      "Gradient Descent(566/999): loss=15.386193543357857, w0=73.28288455467873, w1=13.501560958165436\n",
      "Gradient Descent(567/999): loss=15.386187460434739, w0=73.28299492915299, w1=13.501342472933672\n",
      "Gradient Descent(568/999): loss=15.386181498561793, w0=73.28310419988252, w1=13.501126172554226\n",
      "Gradient Descent(569/999): loss=15.38617565533012, w0=73.28321237790475, w1=13.500912035178574\n",
      "Gradient Descent(570/999): loss=15.386169928378754, w0=73.28331947414675, w1=13.50070003917668\n",
      "Gradient Descent(571/999): loss=15.386164315393724, w0=73.28342549942633, w1=13.500490163134803\n",
      "Gradient Descent(572/999): loss=15.386158814107095, w0=73.28353046445312, w1=13.500282385853344\n",
      "Gradient Descent(573/999): loss=15.386153422296067, w0=73.28363437982965, w1=13.500076686344702\n",
      "Gradient Descent(574/999): loss=15.386148137782081, w0=73.2837372560524, w1=13.499873043831146\n",
      "Gradient Descent(575/999): loss=15.386142958429922, w0=73.28383910351293, w1=13.499671437742725\n",
      "Gradient Descent(576/999): loss=15.386137882146874, w0=73.28393993249885, w1=13.499471847715188\n",
      "Gradient Descent(577/999): loss=15.386132906881853, w0=73.28403975319492, w1=13.499274253587927\n",
      "Gradient Descent(578/999): loss=15.38612803062461, w0=73.28413857568403, w1=13.499078635401938\n",
      "Gradient Descent(579/999): loss=15.386123251404884, w0=73.28423640994824, w1=13.498884973397809\n",
      "Gradient Descent(580/999): loss=15.386118567291632, w0=73.2843332658698, w1=13.498693248013721\n",
      "Gradient Descent(581/999): loss=15.386113976392238, w0=73.28442915323215, w1=13.498503439883475\n",
      "Gradient Descent(582/999): loss=15.386109476851736, w0=73.28452408172089, w1=13.49831552983453\n",
      "Gradient Descent(583/999): loss=15.38610506685209, w0=73.28461806092473, w1=13.498129498886074\n",
      "Gradient Descent(584/999): loss=15.386100744611438, w0=73.28471110033654, w1=13.497945328247104\n",
      "Gradient Descent(585/999): loss=15.386096508383375, w0=73.28480320935422, w1=13.497762999314523\n",
      "Gradient Descent(586/999): loss=15.38609235645625, w0=73.28489439728173, w1=13.497582493671267\n",
      "Gradient Descent(587/999): loss=15.386088287152479, w0=73.28498467332997, w1=13.497403793084445\n",
      "Gradient Descent(588/999): loss=15.386084298827848, w0=73.28507404661772, w1=13.49722687950349\n",
      "Gradient Descent(589/999): loss=15.386080389870878, w0=73.2851625261726, w1=13.497051735058346\n",
      "Gradient Descent(590/999): loss=15.386076558702154, w0=73.28525012093192, w1=13.496878342057652\n",
      "Gradient Descent(591/999): loss=15.386072803773684, w0=73.28533683974365, w1=13.496706682986966\n",
      "Gradient Descent(592/999): loss=15.386069123568296, w0=73.28542269136726, w1=13.496536740506986\n",
      "Gradient Descent(593/999): loss=15.386065516598988, w0=73.28550768447464, w1=13.496368497451806\n",
      "Gradient Descent(594/999): loss=15.386061981408377, w0=73.28559182765095, w1=13.496201936827179\n",
      "Gradient Descent(595/999): loss=15.386058516568053, w0=73.28567512939549, w1=13.496037041808798\n",
      "Gradient Descent(596/999): loss=15.386055120678053, w0=73.28575759812259, w1=13.4958737957406\n",
      "Gradient Descent(597/999): loss=15.386051792366267, w0=73.28583924216241, w1=13.495712182133085\n",
      "Gradient Descent(598/999): loss=15.386048530287884, w0=73.28592006976184, w1=13.495552184661644\n",
      "Gradient Descent(599/999): loss=15.38604533312486, w0=73.28600008908528, w1=13.495393787164918\n",
      "Gradient Descent(600/999): loss=15.386042199585377, w0=73.28607930821548, w1=13.49523697364316\n",
      "Gradient Descent(601/999): loss=15.386039128403336, w0=73.28615773515438, w1=13.495081728256618\n",
      "Gradient Descent(602/999): loss=15.386036118337815, w0=73.28623537782389, w1=13.494928035323943\n",
      "Gradient Descent(603/999): loss=15.386033168172597, w0=73.28631224406669, w1=13.494775879320594\n",
      "Gradient Descent(604/999): loss=15.386030276715669, w0=73.28638834164708, w1=13.494625244877279\n",
      "Gradient Descent(605/999): loss=15.386027442798728, w0=73.28646367825166, w1=13.494476116778396\n",
      "Gradient Descent(606/999): loss=15.386024665276741, w0=73.2865382614902, w1=13.494328479960503\n",
      "Gradient Descent(607/999): loss=15.386021943027439, w0=73.28661209889634, w1=13.494182319510788\n",
      "Gradient Descent(608/999): loss=15.386019274950897, w0=73.28668519792843, w1=13.494037620665571\n",
      "Gradient Descent(609/999): loss=15.38601665996908, w0=73.2867575659702, w1=13.493894368808807\n",
      "Gradient Descent(610/999): loss=15.3860140970254, w0=73.28682921033156, w1=13.493752549470608\n",
      "Gradient Descent(611/999): loss=15.3860115850843, w0=73.2869001382493, w1=13.493612148325793\n",
      "Gradient Descent(612/999): loss=15.386009123130826, w0=73.28697035688785, w1=13.493473151192426\n",
      "Gradient Descent(613/999): loss=15.38600671017023, w0=73.28703987334002, w1=13.493335544030392\n",
      "Gradient Descent(614/999): loss=15.386004345227546, w0=73.28710869462768, w1=13.493199312939979\n",
      "Gradient Descent(615/999): loss=15.386002027347224, w0=73.28717682770245, w1=13.493064444160469\n",
      "Gradient Descent(616/999): loss=15.385999755592719, w0=73.28724427944648, w1=13.492930924068755\n",
      "Gradient Descent(617/999): loss=15.38599752904613, w0=73.28731105667308, w1=13.492798739177958\n",
      "Gradient Descent(618/999): loss=15.385995346807816, w0=73.2873771661274, w1=13.49266787613607\n",
      "Gradient Descent(619/999): loss=15.385993207996044, w0=73.28744261448718, w1=13.492538321724599\n",
      "Gradient Descent(620/999): loss=15.385991111746629, w0=73.28750740836335, w1=13.492410062857243\n",
      "Gradient Descent(621/999): loss=15.385989057212576, w0=73.28757155430077, w1=13.49228308657856\n",
      "Gradient Descent(622/999): loss=15.385987043563752, w0=73.28763505877882, w1=13.492157380062665\n",
      "Gradient Descent(623/999): loss=15.385985069986537, w0=73.28769792821208, w1=13.492032930611929\n",
      "Gradient Descent(624/999): loss=15.385983135683508, w0=73.28776016895101, w1=13.4919097256557\n",
      "Gradient Descent(625/999): loss=15.385981239873113, w0=73.28782178728255, w1=13.491787752749033\n",
      "Gradient Descent(626/999): loss=15.385979381789342, w0=73.28788278943078, w1=13.491666999571434\n",
      "Gradient Descent(627/999): loss=15.385977560681443, w0=73.28794318155752, w1=13.49154745392561\n",
      "Gradient Descent(628/999): loss=15.385975775813584, w0=73.288002969763, w1=13.491429103736245\n",
      "Gradient Descent(629/999): loss=15.3859740264646, w0=73.28806216008643, w1=13.491311937048772\n",
      "Gradient Descent(630/999): loss=15.385972311927658, w0=73.28812075850661, w1=13.491195942028176\n",
      "Gradient Descent(631/999): loss=15.385970631510006, w0=73.2881787709426, w1=13.491081106957784\n",
      "Gradient Descent(632/999): loss=15.385968984532658, w0=73.28823620325421, w1=13.490967420238096\n",
      "Gradient Descent(633/999): loss=15.385967370330164, w0=73.28829306124273, w1=13.490854870385606\n",
      "Gradient Descent(634/999): loss=15.3859657882503, w0=73.28834935065134, w1=13.49074344603164\n",
      "Gradient Descent(635/999): loss=15.385964237653825, w0=73.28840507716588, w1=13.490633135921215\n",
      "Gradient Descent(636/999): loss=15.385962717914218, w0=73.28846024641527, w1=13.490523928911893\n",
      "Gradient Descent(637/999): loss=15.38596122841743, w0=73.28851486397217, w1=13.490415813972664\n",
      "Gradient Descent(638/999): loss=15.385959768561628, w0=73.2885689353535, w1=13.490308780182827\n",
      "Gradient Descent(639/999): loss=15.385958337756957, w0=73.28862246602101, w1=13.49020281673089\n",
      "Gradient Descent(640/999): loss=15.3859569354253, w0=73.28867546138186, w1=13.490097912913471\n",
      "Gradient Descent(641/999): loss=15.385955561000042, w0=73.2887279267891, w1=13.489994058134227\n",
      "Gradient Descent(642/999): loss=15.385954213925844, w0=73.28877986754226, w1=13.489891241902775\n",
      "Gradient Descent(643/999): loss=15.385952893658425, w0=73.28883128888789, w1=13.489789453833637\n",
      "Gradient Descent(644/999): loss=15.38595159966433, w0=73.28888219602007, w1=13.489688683645191\n",
      "Gradient Descent(645/999): loss=15.385950331420714, w0=73.28893259408092, w1=13.48958892115863\n",
      "Gradient Descent(646/999): loss=15.385949088415146, w0=73.28898248816117, w1=13.489490156296934\n",
      "Gradient Descent(647/999): loss=15.385947870145388, w0=73.28903188330061, w1=13.489392379083856\n",
      "Gradient Descent(648/999): loss=15.385946676119202, w0=73.28908078448866, w1=13.489295579642908\n",
      "Gradient Descent(649/999): loss=15.385945505854133, w0=73.28912919666483, w1=13.48919974819637\n",
      "Gradient Descent(650/999): loss=15.385944358877342, w0=73.28917712471923, w1=13.489104875064296\n",
      "Gradient Descent(651/999): loss=15.385943234725387, w0=73.28922457349309, w1=13.489010950663543\n",
      "Gradient Descent(652/999): loss=15.385942132944058, w0=73.28927154777921, w1=13.488917965506799\n",
      "Gradient Descent(653/999): loss=15.385941053088175, w0=73.28931805232247, w1=13.488825910201621\n",
      "Gradient Descent(654/999): loss=15.385939994721426, w0=73.2893640918203, w1=13.488734775449496\n",
      "Gradient Descent(655/999): loss=15.385938957416172, w0=73.28940967092315, w1=13.48864455204489\n",
      "Gradient Descent(656/999): loss=15.385937940753298, w0=73.28945479423497, w1=13.488555230874333\n",
      "Gradient Descent(657/999): loss=15.385936944322012, w0=73.28949946631367, w1=13.48846680291548\n",
      "Gradient Descent(658/999): loss=15.385935967719709, w0=73.28954369167158, w1=13.488379259236217\n",
      "Gradient Descent(659/999): loss=15.385935010551792, w0=73.28958747477591, w1=13.488292590993744\n",
      "Gradient Descent(660/999): loss=15.385934072431514, w0=73.28963082004921, w1=13.488206789433697\n",
      "Gradient Descent(661/999): loss=15.385933152979833, w0=73.28967373186977, w1=13.48812184588925\n",
      "Gradient Descent(662/999): loss=15.385932251825242, w0=73.28971621457212, w1=13.488037751780247\n",
      "Gradient Descent(663/999): loss=15.385931368603622, w0=73.28975827244746, w1=13.487954498612336\n",
      "Gradient Descent(664/999): loss=15.385930502958118, w0=73.28979990974403, w1=13.487872077976103\n",
      "Gradient Descent(665/999): loss=15.385929654538957, w0=73.28984113066764, w1=13.487790481546233\n",
      "Gradient Descent(666/999): loss=15.385928823003336, w0=73.28988193938201, w1=13.48770970108066\n",
      "Gradient Descent(667/999): loss=15.385928008015274, w0=73.28992234000924, w1=13.487629728419744\n",
      "Gradient Descent(668/999): loss=15.385927209245475, w0=73.2899623366302, w1=13.487550555485438\n",
      "Gradient Descent(669/999): loss=15.385926426371196, w0=73.29000193328494, w1=13.487472174280473\n",
      "Gradient Descent(670/999): loss=15.385925659076113, w0=73.29004113397315, w1=13.487394576887558\n",
      "Gradient Descent(671/999): loss=15.385924907050203, w0=73.29007994265447, w1=13.487317755468574\n",
      "Gradient Descent(672/999): loss=15.385924169989611, w0=73.29011836324898, w1=13.487241702263779\n",
      "Gradient Descent(673/999): loss=15.38592344759652, w0=73.29015639963754, w1=13.487166409591032\n",
      "Gradient Descent(674/999): loss=15.385922739579057, w0=73.29019405566221, w1=13.487091869845012\n",
      "Gradient Descent(675/999): loss=15.385922045651137, w0=73.29023133512665, w1=13.487018075496453\n",
      "Gradient Descent(676/999): loss=15.385921365532385, w0=73.29026824179644, w1=13.486945019091378\n",
      "Gradient Descent(677/999): loss=15.385920698947995, w0=73.29030477939953, w1=13.486872693250355\n",
      "Gradient Descent(678/999): loss=15.385920045628634, w0=73.29034095162659, w1=13.486801090667742\n",
      "Gradient Descent(679/999): loss=15.38591940531033, w0=73.29037676213137, w1=13.486730204110955\n",
      "Gradient Descent(680/999): loss=15.38591877773436, w0=73.29041221453112, w1=13.486660026419736\n",
      "Gradient Descent(681/999): loss=15.385918162647151, w0=73.29044731240685, w1=13.48659055050543\n",
      "Gradient Descent(682/999): loss=15.38591755980018, w0=73.29048205930384, w1=13.486521769350265\n",
      "Gradient Descent(683/999): loss=15.385916968949857, w0=73.29051645873186, w1=13.486453676006652\n",
      "Gradient Descent(684/999): loss=15.385916389857462, w0=73.29055051416559, w1=13.486386263596476\n",
      "Gradient Descent(685/999): loss=15.385915822289006, w0=73.29058422904498, w1=13.486319525310401\n",
      "Gradient Descent(686/999): loss=15.385915266015159, w0=73.29061760677558, w1=13.486253454407187\n",
      "Gradient Descent(687/999): loss=15.385914720811162, w0=73.29065065072888, w1=13.486188044213005\n",
      "Gradient Descent(688/999): loss=15.385914186456723, w0=73.29068336424264, w1=13.486123288120766\n",
      "Gradient Descent(689/999): loss=15.385913662735941, w0=73.29071575062126, w1=13.486059179589448\n",
      "Gradient Descent(690/999): loss=15.3859131494372, w0=73.2907478131361, w1=13.485995712143444\n",
      "Gradient Descent(691/999): loss=15.385912646353106, w0=73.29077955502578, w1=13.4859328793719\n",
      "Gradient Descent(692/999): loss=15.385912153280383, w0=73.29081097949657, w1=13.485870674928071\n",
      "Gradient Descent(693/999): loss=15.385911670019809, w0=73.29084208972266, w1=13.485809092528681\n",
      "Gradient Descent(694/999): loss=15.38591119637612, w0=73.29087288884648, w1=13.485748125953284\n",
      "Gradient Descent(695/999): loss=15.385910732157942, w0=73.29090337997907, w1=13.485687769043642\n",
      "Gradient Descent(696/999): loss=15.385910277177702, w0=73.29093356620034, w1=13.485628015703096\n",
      "Gradient Descent(697/999): loss=15.38590983125157, w0=73.29096345055939, w1=13.485568859895956\n",
      "Gradient Descent(698/999): loss=15.38590939419937, w0=73.29099303607485, w1=13.485510295646886\n",
      "Gradient Descent(699/999): loss=15.385908965844507, w0=73.29102232573516, w1=13.485452317040307\n",
      "Gradient Descent(700/999): loss=15.385908546013907, w0=73.29105132249886, w1=13.485394918219795\n",
      "Gradient Descent(701/999): loss=15.385908134537935, w0=73.29108002929492, w1=13.485338093387487\n",
      "Gradient Descent(702/999): loss=15.385907731250336, w0=73.29110844902301, w1=13.485281836803502\n",
      "Gradient Descent(703/999): loss=15.385907335988158, w0=73.29113658455384, w1=13.485226142785358\n",
      "Gradient Descent(704/999): loss=15.3859069485917, w0=73.29116443872935, w1=13.485171005707395\n",
      "Gradient Descent(705/999): loss=15.385906568904431, w0=73.2911920143631, w1=13.485116420000212\n",
      "Gradient Descent(706/999): loss=15.385906196772936, w0=73.29121931424052, w1=13.4850623801501\n",
      "Gradient Descent(707/999): loss=15.38590583204686, w0=73.29124634111916, w1=13.48500888069849\n",
      "Gradient Descent(708/999): loss=15.385905474578834, w0=73.29127309772902, w1=13.484955916241397\n",
      "Gradient Descent(709/999): loss=15.38590512422442, w0=73.29129958677278, w1=13.484903481428873\n",
      "Gradient Descent(710/999): loss=15.385904780842058, w0=73.29132581092611, w1=13.484851570964475\n",
      "Gradient Descent(711/999): loss=15.385904444293006, w0=73.2913517728379, w1=13.48480017960472\n",
      "Gradient Descent(712/999): loss=15.38590411444128, w0=73.29137747513057, w1=13.484749302158564\n",
      "Gradient Descent(713/999): loss=15.385903791153606, w0=73.29140292040032, w1=13.484698933486868\n",
      "Gradient Descent(714/999): loss=15.385903474299354, w0=73.29142811121737, w1=13.48464906850189\n",
      "Gradient Descent(715/999): loss=15.385903163750502, w0=73.29145305012625, w1=13.484599702166761\n",
      "Gradient Descent(716/999): loss=15.385902859381568, w0=73.29147773964604, w1=13.484550829494983\n",
      "Gradient Descent(717/999): loss=15.385902561069583, w0=73.29150218227063, w1=13.484502445549925\n",
      "Gradient Descent(718/999): loss=15.385902268694004, w0=73.29152638046898, w1=13.484454545444317\n",
      "Gradient Descent(719/999): loss=15.385901982136696, w0=73.29155033668535, w1=13.484407124339764\n",
      "Gradient Descent(720/999): loss=15.385901701281881, w0=73.29157405333955, w1=13.484360177446257\n",
      "Gradient Descent(721/999): loss=15.385901426016076, w0=73.2915975328272, w1=13.484313700021685\n",
      "Gradient Descent(722/999): loss=15.385901156228062, w0=73.29162077751998, w1=13.484267687371359\n",
      "Gradient Descent(723/999): loss=15.38590089180883, w0=73.29164378976583, w1=13.484222134847537\n",
      "Gradient Descent(724/999): loss=15.385900632651538, w0=73.29166657188922, w1=13.484177037848951\n",
      "Gradient Descent(725/999): loss=15.385900378651481, w0=73.29168912619139, w1=13.484132391820353\n",
      "Gradient Descent(726/999): loss=15.38590012970602, w0=73.29171145495053, w1=13.48408819225204\n",
      "Gradient Descent(727/999): loss=15.385899885714576, w0=73.29173356042207, w1=13.48404443467941\n",
      "Gradient Descent(728/999): loss=15.38589964657856, w0=73.2917554448389, w1=13.484001114682506\n",
      "Gradient Descent(729/999): loss=15.38589941220135, w0=73.29177711041156, w1=13.483958227885571\n",
      "Gradient Descent(730/999): loss=15.38589918248825, w0=73.2917985593285, w1=13.483915769956607\n",
      "Gradient Descent(731/999): loss=15.385898957346438, w0=73.29181979375626, w1=13.483873736606931\n",
      "Gradient Descent(732/999): loss=15.38589873668495, w0=73.29184081583975, w1=13.483832123590751\n",
      "Gradient Descent(733/999): loss=15.385898520414624, w0=73.2918616277024, w1=13.483790926704735\n",
      "Gradient Descent(734/999): loss=15.38589830844808, w0=73.29188223144644, w1=13.483750141787578\n",
      "Gradient Descent(735/999): loss=15.385898100699665, w0=73.29190262915303, w1=13.483709764719592\n",
      "Gradient Descent(736/999): loss=15.385897897085448, w0=73.29192282288255, w1=13.483669791422287\n",
      "Gradient Descent(737/999): loss=15.385897697523149, w0=73.29194281467478, w1=13.483630217857954\n",
      "Gradient Descent(738/999): loss=15.385897501932146, w0=73.29196260654909, w1=13.483591040029264\n",
      "Gradient Descent(739/999): loss=15.385897310233402, w0=73.29198220050465, w1=13.483552253978862\n",
      "Gradient Descent(740/999): loss=15.385897122349462, w0=73.29200159852066, w1=13.483513855788964\n",
      "Gradient Descent(741/999): loss=15.385896938204413, w0=73.29202080255651, w1=13.483475841580965\n",
      "Gradient Descent(742/999): loss=15.385896757723849, w0=73.292039814552, w1=13.483438207515047\n",
      "Gradient Descent(743/999): loss=15.38589658083485, w0=73.29205863642753, w1=13.483400949789786\n",
      "Gradient Descent(744/999): loss=15.385896407465943, w0=73.2920772700843, w1=13.483364064641778\n",
      "Gradient Descent(745/999): loss=15.385896237547076, w0=73.29209571740452, w1=13.483327548345251\n",
      "Gradient Descent(746/999): loss=15.385896071009594, w0=73.29211398025153, w1=13.483291397211689\n",
      "Gradient Descent(747/999): loss=15.385895907786207, w0=73.29213206047007, w1=13.483255607589463\n",
      "Gradient Descent(748/999): loss=15.385895747810967, w0=73.29214995988642, w1=13.483220175863458\n",
      "Gradient Descent(749/999): loss=15.385895591019233, w0=73.29216768030861, w1=13.483185098454713\n",
      "Gradient Descent(750/999): loss=15.385895437347656, w0=73.29218522352657, w1=13.483150371820058\n",
      "Gradient Descent(751/999): loss=15.385895286734144, w0=73.29220259131236, w1=13.483115992451747\n",
      "Gradient Descent(752/999): loss=15.385895139117839, w0=73.29221978542029, w1=13.48308195687712\n",
      "Gradient Descent(753/999): loss=15.385894994439097, w0=73.29223680758713, w1=13.48304826165824\n",
      "Gradient Descent(754/999): loss=15.385894852639467, w0=73.2922536595323, w1=13.483014903391549\n",
      "Gradient Descent(755/999): loss=15.385894713661646, w0=73.29227034295803, w1=13.482981878707523\n",
      "Gradient Descent(756/999): loss=15.385894577449484, w0=73.2922868595495, w1=13.482949184270339\n",
      "Gradient Descent(757/999): loss=15.385894443947942, w0=73.29230321097506, w1=13.482916816777527\n",
      "Gradient Descent(758/999): loss=15.385894313103083, w0=73.29231939888636, w1=13.482884772959641\n",
      "Gradient Descent(759/999): loss=15.385894184862037, w0=73.29233542491855, w1=13.482853049579935\n",
      "Gradient Descent(760/999): loss=15.385894059172989, w0=73.29235129069042, w1=13.482821643434026\n",
      "Gradient Descent(761/999): loss=15.38589393598515, w0=73.29236699780456, w1=13.482790551349575\n",
      "Gradient Descent(762/999): loss=15.385893815248753, w0=73.29238254784757, w1=13.48275977018597\n",
      "Gradient Descent(763/999): loss=15.385893696915007, w0=73.29239794239014, w1=13.482729296834\n",
      "Gradient Descent(764/999): loss=15.385893580936106, w0=73.29241318298729, w1=13.48269912821555\n",
      "Gradient Descent(765/999): loss=15.385893467265179, w0=73.29242827117847, w1=13.482669261283286\n",
      "Gradient Descent(766/999): loss=15.385893355856306, w0=73.29244320848774, w1=13.482639693020344\n",
      "Gradient Descent(767/999): loss=15.385893246664473, w0=73.29245799642392, w1=13.48261042044003\n",
      "Gradient Descent(768/999): loss=15.385893139645557, w0=73.29247263648074, w1=13.482581440585522\n",
      "Gradient Descent(769/999): loss=15.385893034756311, w0=73.29248713013698, w1=13.482552750529557\n",
      "Gradient Descent(770/999): loss=15.385892931954368, w0=73.29250147885666, w1=13.482524347374152\n",
      "Gradient Descent(771/999): loss=15.38589283119818, w0=73.29251568408915, w1=13.482496228250302\n",
      "Gradient Descent(772/999): loss=15.385892732447042, w0=73.29252974726931, w1=13.482468390317688\n",
      "Gradient Descent(773/999): loss=15.38589263566105, w0=73.29254366981768, w1=13.482440830764402\n",
      "Gradient Descent(774/999): loss=15.385892540801102, w0=73.29255745314055, w1=13.482413546806649\n",
      "Gradient Descent(775/999): loss=15.385892447828862, w0=73.29257109863019, w1=13.482386535688473\n",
      "Gradient Descent(776/999): loss=15.385892356706774, w0=73.29258460766493, w1=13.482359794681479\n",
      "Gradient Descent(777/999): loss=15.385892267398015, w0=73.29259798160933, w1=13.482333321084555\n",
      "Gradient Descent(778/999): loss=15.385892179866499, w0=73.2926112218143, w1=13.4823071122236\n",
      "Gradient Descent(779/999): loss=15.385892094076862, w0=73.29262432961721, w1=13.482281165451255\n",
      "Gradient Descent(780/999): loss=15.385892009994437, w0=73.29263730634209, w1=13.482255478146632\n",
      "Gradient Descent(781/999): loss=15.385891927585254, w0=73.29265015329972, w1=13.482230047715056\n",
      "Gradient Descent(782/999): loss=15.385891846816012, w0=73.29266287178777, w1=13.482204871587797\n",
      "Gradient Descent(783/999): loss=15.38589176765408, w0=73.29267546309094, w1=13.482179947221809\n",
      "Gradient Descent(784/999): loss=15.385891690067467, w0=73.29268792848109, w1=13.482155272099481\n",
      "Gradient Descent(785/999): loss=15.38589161402483, w0=73.29270026921733, w1=13.482130843728378\n",
      "Gradient Descent(786/999): loss=15.385891539495438, w0=73.29271248654621, w1=13.482106659640984\n",
      "Gradient Descent(787/999): loss=15.385891466449186, w0=73.29272458170179, w1=13.482082717394464\n",
      "Gradient Descent(788/999): loss=15.385891394856552, w0=73.29273655590582, w1=13.48205901457041\n",
      "Gradient Descent(789/999): loss=15.385891324688613, w0=73.2927484103678, w1=13.482035548774597\n",
      "Gradient Descent(790/999): loss=15.385891255917013, w0=73.29276014628518, w1=13.482012317636741\n",
      "Gradient Descent(791/999): loss=15.385891188513972, w0=73.29277176484338, w1=13.481989318810264\n",
      "Gradient Descent(792/999): loss=15.385891122452245, w0=73.292783267216, w1=13.481966549972052\n",
      "Gradient Descent(793/999): loss=15.385891057705152, w0=73.29279465456489, w1=13.481944008822222\n",
      "Gradient Descent(794/999): loss=15.385890994246525, w0=73.2928059280403, w1=13.48192169308389\n",
      "Gradient Descent(795/999): loss=15.385890932050726, w0=73.29281708878095, w1=13.481899600502942\n",
      "Gradient Descent(796/999): loss=15.385890871092618, w0=73.2928281379142, w1=13.481877728847802\n",
      "Gradient Descent(797/999): loss=15.385890811347581, w0=73.2928390765561, w1=13.481856075909215\n",
      "Gradient Descent(798/999): loss=15.38589075279147, w0=73.2928499058116, w1=13.481834639500013\n",
      "Gradient Descent(799/999): loss=15.385890695400624, w0=73.29286062677453, w1=13.481813417454903\n",
      "Gradient Descent(800/999): loss=15.385890639151857, w0=73.29287124052783, w1=13.481792407630245\n",
      "Gradient Descent(801/999): loss=15.385890584022441, w0=73.2928817481436, w1=13.481771607903832\n",
      "Gradient Descent(802/999): loss=15.3858905299901, w0=73.29289215068322, w1=13.481751016174684\n",
      "Gradient Descent(803/999): loss=15.385890477033, w0=73.29290244919744, w1=13.481730630362827\n",
      "Gradient Descent(804/999): loss=15.38589042512975, w0=73.29291264472651, w1=13.481710448409089\n",
      "Gradient Descent(805/999): loss=15.385890374259372, w0=73.2929227383003, w1=13.48169046827489\n",
      "Gradient Descent(806/999): loss=15.385890324401316, w0=73.29293273093836, w1=13.481670687942032\n",
      "Gradient Descent(807/999): loss=15.385890275535433, w0=73.29294262365003, w1=13.481651105412501\n",
      "Gradient Descent(808/999): loss=15.385890227641985, w0=73.29295241743459, w1=13.481631718708266\n",
      "Gradient Descent(809/999): loss=15.385890180701614, w0=73.29296211328129, w1=13.481612525871075\n",
      "Gradient Descent(810/999): loss=15.385890134695359, w0=73.29297171216953, w1=13.481593524962255\n",
      "Gradient Descent(811/999): loss=15.385890089604626, w0=73.29298121506889, w1=13.481574714062523\n",
      "Gradient Descent(812/999): loss=15.385890045411198, w0=73.29299062293926, w1=13.481556091271788\n",
      "Gradient Descent(813/999): loss=15.385890002097218, w0=73.29299993673092, w1=13.48153765470896\n",
      "Gradient Descent(814/999): loss=15.38588995964519, w0=73.29300915738466, w1=13.481519402511761\n",
      "Gradient Descent(815/999): loss=15.385889918037956, w0=73.29301828583186, w1=13.481501332836535\n",
      "Gradient Descent(816/999): loss=15.385889877258707, w0=73.29302732299459, w1=13.48148344385806\n",
      "Gradient Descent(817/999): loss=15.385889837290964, w0=73.2930362697857, w1=13.48146573376937\n",
      "Gradient Descent(818/999): loss=15.385889798118578, w0=73.2930451271089, w1=13.481448200781568\n",
      "Gradient Descent(819/999): loss=15.385889759725723, w0=73.29305389585886, w1=13.481430843123643\n",
      "Gradient Descent(820/999): loss=15.385889722096884, w0=73.29306257692133, w1=13.481413659042298\n",
      "Gradient Descent(821/999): loss=15.385889685216863, w0=73.29307117117317, w1=13.481396646801766\n",
      "Gradient Descent(822/999): loss=15.385889649070753, w0=73.29307967948249, w1=13.48137980468364\n",
      "Gradient Descent(823/999): loss=15.385889613643949, w0=73.29308810270872, w1=13.481363130986693\n",
      "Gradient Descent(824/999): loss=15.38588957892214, w0=73.29309644170269, w1=13.481346624026717\n",
      "Gradient Descent(825/999): loss=15.385889544891295, w0=73.29310469730672, w1=13.48133028213634\n",
      "Gradient Descent(826/999): loss=15.385889511537663, w0=73.2931128703547, w1=13.481314103664868\n",
      "Gradient Descent(827/999): loss=15.38588947884777, w0=73.29312096167222, w1=13.48129808697811\n",
      "Gradient Descent(828/999): loss=15.385889446808404, w0=73.29312897207654, w1=13.48128223045822\n",
      "Gradient Descent(829/999): loss=15.385889415406622, w0=73.29313690237683, w1=13.481266532503527\n",
      "Gradient Descent(830/999): loss=15.385889384629735, w0=73.29314475337411, w1=13.481250991528382\n",
      "Gradient Descent(831/999): loss=15.385889354465307, w0=73.29315252586142, w1=13.481235605962988\n",
      "Gradient Descent(832/999): loss=15.385889324901152, w0=73.29316022062385, w1=13.48122037425325\n",
      "Gradient Descent(833/999): loss=15.385889295925326, w0=73.29316783843866, w1=13.481205294860608\n",
      "Gradient Descent(834/999): loss=15.385889267526116, w0=73.29317538007533, w1=13.481190366261892\n",
      "Gradient Descent(835/999): loss=15.38588923969205, w0=73.29318284629562, w1=13.481175586949163\n",
      "Gradient Descent(836/999): loss=15.385889212411884, w0=73.29319023785372, w1=13.481160955429562\n",
      "Gradient Descent(837/999): loss=15.385889185674593, w0=73.29319755549623, w1=13.481146470225157\n",
      "Gradient Descent(838/999): loss=15.385889159469373, w0=73.29320479996233, w1=13.481132129872796\n",
      "Gradient Descent(839/999): loss=15.38588913378564, w0=73.29321197198375, w1=13.481117932923958\n",
      "Gradient Descent(840/999): loss=15.385889108613009, w0=73.29321907228497, w1=13.481103877944609\n",
      "Gradient Descent(841/999): loss=15.385889083941313, w0=73.29322610158317, w1=13.481089963515053\n",
      "Gradient Descent(842/999): loss=15.385889059760588, w0=73.29323306058839, w1=13.481076188229792\n",
      "Gradient Descent(843/999): loss=15.385889036061059, w0=73.29323995000355, w1=13.481062550697384\n",
      "Gradient Descent(844/999): loss=15.385889012833148, w0=73.29324677052458, w1=13.481049049540301\n",
      "Gradient Descent(845/999): loss=15.385888990067475, w0=73.29325352284039, w1=13.481035683394788\n",
      "Gradient Descent(846/999): loss=15.385888967754834, w0=73.29326020763304, w1=13.48102245091073\n",
      "Gradient Descent(847/999): loss=15.385888945886219, w0=73.29326682557776, w1=13.481009350751513\n",
      "Gradient Descent(848/999): loss=15.385888924452791, w0=73.29327337734303, w1=13.480996381593888\n",
      "Gradient Descent(849/999): loss=15.385888903445885, w0=73.29327986359066, w1=13.48098354212784\n",
      "Gradient Descent(850/999): loss=15.385888882857017, w0=73.2932862849758, w1=13.480970831056451\n",
      "Gradient Descent(851/999): loss=15.385888862677865, w0=73.2932926421471, w1=13.480958247095778\n",
      "Gradient Descent(852/999): loss=15.38588884290028, w0=73.29329893574668, w1=13.48094578897471\n",
      "Gradient Descent(853/999): loss=15.385888823516272, w0=73.29330516641026, w1=13.480933455434853\n",
      "Gradient Descent(854/999): loss=15.385888804518, w0=73.29331133476721, w1=13.480921245230395\n",
      "Gradient Descent(855/999): loss=15.385888785897798, w0=73.29331744144059, w1=13.48090915712798\n",
      "Gradient Descent(856/999): loss=15.385888767648137, w0=73.29332348704723, w1=13.48089718990659\n",
      "Gradient Descent(857/999): loss=15.385888749761644, w0=73.29332947219781, w1=13.480885342357416\n",
      "Gradient Descent(858/999): loss=15.385888732231095, w0=73.29333539749689, w1=13.480873613283732\n",
      "Gradient Descent(859/999): loss=15.3858887150494, w0=73.29334126354297, w1=13.480862001500785\n",
      "Gradient Descent(860/999): loss=15.385888698209621, w0=73.29334707092859, w1=13.480850505835669\n",
      "Gradient Descent(861/999): loss=15.385888681704955, w0=73.29335282024036, w1=13.480839125127202\n",
      "Gradient Descent(862/999): loss=15.385888665528732, w0=73.293358512059, w1=13.48082785822582\n",
      "Gradient Descent(863/999): loss=15.385888649674415, w0=73.29336414695946, w1=13.480816703993453\n",
      "Gradient Descent(864/999): loss=15.385888634135597, w0=73.29336972551091, w1=13.480805661303409\n",
      "Gradient Descent(865/999): loss=15.385888618906005, w0=73.29337524827686, w1=13.480794729040266\n",
      "Gradient Descent(866/999): loss=15.38588860397948, w0=73.29338071581515, w1=13.480783906099754\n",
      "Gradient Descent(867/999): loss=15.385888589349994, w0=73.29338612867805, w1=13.480773191388646\n",
      "Gradient Descent(868/999): loss=15.385888575011634, w0=73.29339148741232, w1=13.480762583824651\n",
      "Gradient Descent(869/999): loss=15.385888560958609, w0=73.29339679255925, w1=13.480752082336295\n",
      "Gradient Descent(870/999): loss=15.385888547185237, w0=73.29340204465471, w1=13.480741685862823\n",
      "Gradient Descent(871/999): loss=15.385888533685955, w0=73.29340724422921, w1=13.480731393354084\n",
      "Gradient Descent(872/999): loss=15.38588852045531, w0=73.29341239180798, w1=13.480721203770434\n",
      "Gradient Descent(873/999): loss=15.385888507487957, w0=73.29341748791094, w1=13.48071111608262\n",
      "Gradient Descent(874/999): loss=15.385888494778651, w0=73.29342253305289, w1=13.480701129271685\n",
      "Gradient Descent(875/999): loss=15.385888482322258, w0=73.29342752774342, w1=13.480691242328858\n",
      "Gradient Descent(876/999): loss=15.385888470113755, w0=73.29343247248704, w1=13.480681454255459\n",
      "Gradient Descent(877/999): loss=15.385888458148193, w0=73.29343736778323, w1=13.480671764062794\n",
      "Gradient Descent(878/999): loss=15.385888446420749, w0=73.29344221412644, w1=13.480662170772057\n",
      "Gradient Descent(879/999): loss=15.385888434926683, w0=73.29344701200623, w1=13.480652673414227\n",
      "Gradient Descent(880/999): loss=15.385888423661346, w0=73.29345176190722, w1=13.480643271029974\n",
      "Gradient Descent(881/999): loss=15.385888412620188, w0=73.2934564643092, w1=13.480633962669565\n",
      "Gradient Descent(882/999): loss=15.385888401798752, w0=73.29346111968717, w1=13.48062474739276\n",
      "Gradient Descent(883/999): loss=15.385888391192662, w0=73.29346572851135, w1=13.480615624268722\n",
      "Gradient Descent(884/999): loss=15.385888380797633, w0=73.29347029124729, w1=13.480606592375926\n",
      "Gradient Descent(885/999): loss=15.385888370609466, w0=73.29347480835587, w1=13.480597650802057\n",
      "Gradient Descent(886/999): loss=15.385888360624044, w0=73.29347928029335, w1=13.480588798643927\n",
      "Gradient Descent(887/999): loss=15.385888350837329, w0=73.29348370751147, w1=13.480580035007378\n",
      "Gradient Descent(888/999): loss=15.385888341245373, w0=73.2934880904574, w1=13.480571359007195\n",
      "Gradient Descent(889/999): loss=15.385888331844294, w0=73.29349242957387, w1=13.480562769767014\n",
      "Gradient Descent(890/999): loss=15.385888322630297, w0=73.29349672529919, w1=13.480554266419235\n",
      "Gradient Descent(891/999): loss=15.385888313599658, w0=73.29350097806726, w1=13.480545848104933\n",
      "Gradient Descent(892/999): loss=15.385888304748729, w0=73.29350518830763, w1=13.480537513973774\n",
      "Gradient Descent(893/999): loss=15.385888296073936, w0=73.29350935644561, w1=13.480529263183927\n",
      "Gradient Descent(894/999): loss=15.38588828757177, w0=73.29351348290221, w1=13.480521094901977\n",
      "Gradient Descent(895/999): loss=15.385888279238797, w0=73.29351756809425, w1=13.480513008302848\n",
      "Gradient Descent(896/999): loss=15.385888271071648, w0=73.29352161243436, w1=13.48050500256971\n",
      "Gradient Descent(897/999): loss=15.385888263067029, w0=73.29352561633107, w1=13.480497076893904\n",
      "Gradient Descent(898/999): loss=15.385888255221703, w0=73.2935295801888, w1=13.480489230474856\n",
      "Gradient Descent(899/999): loss=15.385888247532494, w0=73.29353350440796, w1=13.480481462519997\n",
      "Gradient Descent(900/999): loss=15.385888239996303, w0=73.29353738938494, w1=13.480473772244688\n",
      "Gradient Descent(901/999): loss=15.38588823261008, w0=73.29354123551214, w1=13.480466158872131\n",
      "Gradient Descent(902/999): loss=15.385888225370847, w0=73.29354504317807, w1=13.4804586216333\n",
      "Gradient Descent(903/999): loss=15.385888218275667, w0=73.29354881276734, w1=13.480451159766858\n",
      "Gradient Descent(904/999): loss=15.385888211321689, w0=73.29355254466071, w1=13.480443772519079\n",
      "Gradient Descent(905/999): loss=15.385888204506092, w0=73.29355623923516, w1=13.480436459143778\n",
      "Gradient Descent(906/999): loss=15.385888197826128, w0=73.29355989686385, w1=13.48042921890223\n",
      "Gradient Descent(907/999): loss=15.385888191279093, w0=73.29356351791627, w1=13.4804220510631\n",
      "Gradient Descent(908/999): loss=15.385888184862342, w0=73.29356710275816, w1=13.48041495490236\n",
      "Gradient Descent(909/999): loss=15.385888178573287, w0=73.29357065175164, w1=13.480407929703226\n",
      "Gradient Descent(910/999): loss=15.385888172409384, w0=73.29357416525517, w1=13.480400974756083\n",
      "Gradient Descent(911/999): loss=15.385888166368142, w0=73.29357764362366, w1=13.480394089358413\n",
      "Gradient Descent(912/999): loss=15.385888160447118, w0=73.29358108720848, w1=13.480387272814719\n",
      "Gradient Descent(913/999): loss=15.385888154643927, w0=73.29358449635745, w1=13.480380524436463\n",
      "Gradient Descent(914/999): loss=15.38588814895622, w0=73.29358787141493, w1=13.480373843541988\n",
      "Gradient Descent(915/999): loss=15.385888143381697, w0=73.29359121272184, w1=13.480367229456458\n",
      "Gradient Descent(916/999): loss=15.385888137918105, w0=73.29359452061567, w1=13.480360681511785\n",
      "Gradient Descent(917/999): loss=15.385888132563242, w0=73.29359779543057, w1=13.480354199046557\n",
      "Gradient Descent(918/999): loss=15.385888127314937, w0=73.29360103749731, w1=13.480347781405982\n",
      "Gradient Descent(919/999): loss=15.385888122171076, w0=73.29360424714339, w1=13.480341427941813\n",
      "Gradient Descent(920/999): loss=15.385888117129577, w0=73.29360742469301, w1=13.480335138012284\n",
      "Gradient Descent(921/999): loss=15.385888112188402, w0=73.29361057046712, w1=13.480328910982053\n",
      "Gradient Descent(922/999): loss=15.385888107345556, w0=73.29361368478351, w1=13.480322746222123\n",
      "Gradient Descent(923/999): loss=15.385888102599084, w0=73.29361676795672, w1=13.480316643109793\n",
      "Gradient Descent(924/999): loss=15.385888097947067, w0=73.2936198202982, w1=13.480310601028586\n",
      "Gradient Descent(925/999): loss=15.385888093387626, w0=73.29362284211628, w1=13.48030461936819\n",
      "Gradient Descent(926/999): loss=15.38588808891892, w0=73.29362583371616, w1=13.480298697524399\n",
      "Gradient Descent(927/999): loss=15.385888084539136, w0=73.29362879540005, w1=13.480292834899045\n",
      "Gradient Descent(928/999): loss=15.385888080246513, w0=73.2936317274671, w1=13.480287030899945\n",
      "Gradient Descent(929/999): loss=15.385888076039313, w0=73.29363463021348, w1=13.480281284940835\n",
      "Gradient Descent(930/999): loss=15.385888071915833, w0=73.29363750393239, w1=13.480275596441317\n",
      "Gradient Descent(931/999): loss=15.385888067874415, w0=73.29364034891411, w1=13.480269964826794\n",
      "Gradient Descent(932/999): loss=15.385888063913418, w0=73.29364316544603, w1=13.480264389528417\n",
      "Gradient Descent(933/999): loss=15.385888060031249, w0=73.29364595381261, w1=13.480258869983023\n",
      "Gradient Descent(934/999): loss=15.385888056226333, w0=73.29364871429554, w1=13.480253405633084\n",
      "Gradient Descent(935/999): loss=15.385888052497132, w0=73.29365144717364, w1=13.480247995926643\n",
      "Gradient Descent(936/999): loss=15.385888048842144, w0=73.29365415272297, w1=13.480242640317266\n",
      "Gradient Descent(937/999): loss=15.385888045259891, w0=73.2936568312168, w1=13.480237338263985\n",
      "Gradient Descent(938/999): loss=15.385888041748924, w0=73.29365948292568, w1=13.480232089231235\n",
      "Gradient Descent(939/999): loss=15.385888038307824, w0=73.29366210811747, w1=13.480226892688814\n",
      "Gradient Descent(940/999): loss=15.385888034935205, w0=73.29366470705735, w1=13.480221748111816\n",
      "Gradient Descent(941/999): loss=15.385888031629698, w0=73.29366728000782, w1=13.48021665498059\n",
      "Gradient Descent(942/999): loss=15.385888028389973, w0=73.2936698272288, w1=13.480211612780673\n",
      "Gradient Descent(943/999): loss=15.385888025214719, w0=73.29367234897757, w1=13.480206621002758\n",
      "Gradient Descent(944/999): loss=15.385888022102652, w0=73.29367484550885, w1=13.48020167914262\n",
      "Gradient Descent(945/999): loss=15.385888019052514, w0=73.29367731707481, w1=13.480196786701084\n",
      "Gradient Descent(946/999): loss=15.385888016063074, w0=73.29367976392511, w1=13.480191943183964\n",
      "Gradient Descent(947/999): loss=15.38588801313312, w0=73.29368218630691, w1=13.480187148102015\n",
      "Gradient Descent(948/999): loss=15.385888010261478, w0=73.2936845844649, w1=13.480182400970886\n",
      "Gradient Descent(949/999): loss=15.385888007446981, w0=73.2936869586413, w1=13.480177701311067\n",
      "Gradient Descent(950/999): loss=15.385888004688491, w0=73.29368930907594, w1=13.480173048647847\n",
      "Gradient Descent(951/999): loss=15.385888001984894, w0=73.29369163600623, w1=13.480168442511259\n",
      "Gradient Descent(952/999): loss=15.3858879993351, w0=73.29369393966722, w1=13.480163882436036\n",
      "Gradient Descent(953/999): loss=15.385887996738038, w0=73.29369622029161, w1=13.480159367961566\n",
      "Gradient Descent(954/999): loss=15.385887994192654, w0=73.29369847810975, w1=13.48015489863184\n",
      "Gradient Descent(955/999): loss=15.385887991697926, w0=73.29370071334971, w1=13.480150473995412\n",
      "Gradient Descent(956/999): loss=15.38588798925284, w0=73.29370292623726, w1=13.480146093605349\n",
      "Gradient Descent(957/999): loss=15.385887986856417, w0=73.29370511699594, w1=13.480141757019187\n",
      "Gradient Descent(958/999): loss=15.385887984507676, w0=73.29370728584703, w1=13.480137463798885\n",
      "Gradient Descent(959/999): loss=15.38588798220568, w0=73.29370943300961, w1=13.480133213510786\n",
      "Gradient Descent(960/999): loss=15.385887979949493, w0=73.29371155870056, w1=13.48012900572557\n",
      "Gradient Descent(961/999): loss=15.385887977738202, w0=73.29371366313461, w1=13.480124840018204\n",
      "Gradient Descent(962/999): loss=15.385887975570917, w0=73.29371574652431, w1=13.480120715967912\n",
      "Gradient Descent(963/999): loss=15.38588797344676, w0=73.29371780908012, w1=13.480116633158124\n",
      "Gradient Descent(964/999): loss=15.385887971364875, w0=73.29371985101037, w1=13.480112591176432\n",
      "Gradient Descent(965/999): loss=15.38588796932442, w0=73.29372187252132, w1=13.48010858961456\n",
      "Gradient Descent(966/999): loss=15.385887967324567, w0=73.29372387381716, w1=13.480104628068304\n",
      "Gradient Descent(967/999): loss=15.385887965364516, w0=73.29372585510004, w1=13.480100706137511\n",
      "Gradient Descent(968/999): loss=15.385887963443464, w0=73.29372781657008, w1=13.480096823426027\n",
      "Gradient Descent(969/999): loss=15.385887961560645, w0=73.29372975842543, w1=13.480092979541658\n",
      "Gradient Descent(970/999): loss=15.385887959715292, w0=73.29373168086222, w1=13.48008917409613\n",
      "Gradient Descent(971/999): loss=15.385887957906665, w0=73.29373358407466, w1=13.48008540670506\n",
      "Gradient Descent(972/999): loss=15.385887956134026, w0=73.29373546825497, w1=13.480081676987899\n",
      "Gradient Descent(973/999): loss=15.385887954396667, w0=73.29373733359347, w1=13.48007798456791\n",
      "Gradient Descent(974/999): loss=15.385887952693878, w0=73.29373918027859, w1=13.48007432907212\n",
      "Gradient Descent(975/999): loss=15.385887951024975, w0=73.29374100849685, w1=13.48007071013129\n",
      "Gradient Descent(976/999): loss=15.38588794938928, w0=73.29374281843293, w1=13.480067127379868\n",
      "Gradient Descent(977/999): loss=15.38588794778614, w0=73.29374461026966, w1=13.48006358045596\n",
      "Gradient Descent(978/999): loss=15.385887946214899, w0=73.29374638418801, w1=13.480060069001292\n",
      "Gradient Descent(979/999): loss=15.385887944674929, w0=73.29374814036719, w1=13.48005659266117\n",
      "Gradient Descent(980/999): loss=15.385887943165605, w0=73.29374987898457, w1=13.480053151084448\n",
      "Gradient Descent(981/999): loss=15.385887941686315, w0=73.29375160021577, w1=13.480049743923495\n",
      "Gradient Descent(982/999): loss=15.38588794023646, w0=73.29375330423467, w1=13.48004637083415\n",
      "Gradient Descent(983/999): loss=15.38588793881546, w0=73.29375499121338, w1=13.4800430314757\n",
      "Gradient Descent(984/999): loss=15.385887937422737, w0=73.29375666132229, w1=13.480039725510833\n",
      "Gradient Descent(985/999): loss=15.38588793605773, w0=73.29375831473013, w1=13.480036452605615\n",
      "Gradient Descent(986/999): loss=15.385887934719888, w0=73.29375995160387, w1=13.480033212429449\n",
      "Gradient Descent(987/999): loss=15.385887933408666, w0=73.29376157210889, w1=13.480030004655045\n",
      "Gradient Descent(988/999): loss=15.385887932123538, w0=73.29376317640886, w1=13.480026828958385\n",
      "Gradient Descent(989/999): loss=15.385887930863985, w0=73.29376476466582, w1=13.480023685018692\n",
      "Gradient Descent(990/999): loss=15.385887929629497, w0=73.29376633704021, w1=13.480020572518395\n",
      "Gradient Descent(991/999): loss=15.385887928419573, w0=73.29376789369086, w1=13.480017491143101\n",
      "Gradient Descent(992/999): loss=15.38588792723373, w0=73.293769434775, w1=13.480014440581561\n",
      "Gradient Descent(993/999): loss=15.385887926071486, w0=73.2937709604483, w1=13.480011420525637\n",
      "Gradient Descent(994/999): loss=15.385887924932367, w0=73.29377247086487, w1=13.48000843067027\n",
      "Gradient Descent(995/999): loss=15.385887923815917, w0=73.29377396617727, w1=13.480005470713458\n",
      "Gradient Descent(996/999): loss=15.385887922721688, w0=73.29377544653654, w1=13.480002540356214\n",
      "Gradient Descent(997/999): loss=15.385887921649228, w0=73.29377691209223, w1=13.479999639302543\n",
      "Gradient Descent(998/999): loss=15.385887920598115, w0=73.29377836299236, w1=13.479996767259408\n",
      "Gradient Descent(999/999): loss=15.385887919567915, w0=73.29377979938349, w1=13.479993923936703\n"
     ]
    }
   ],
   "source": [
    "test_your_least_squares()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Least squares with a linear basis function model\n",
    "Start from this section, we will use the dataset `dataEx3.csv`.\n",
    "\n",
    "### Implement polynomial basis functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x (50,)\n",
      "shape of y (50,)\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "x, y = load_data()\n",
    "print(\"shape of x {}\".format(x.shape))\n",
    "print(\"shape of y {}\".format(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_poly(x, degree):\n",
    "    \"\"\"polynomial basis functions for input data x, for j=0 up to j=degree.\"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # polynomial basis function: TODO\n",
    "    # this function should return the matrix formed\n",
    "    # by applying the polynomial basis to the input data\n",
    "    # ***************************************************\n",
    "    n = np.shape(x)\n",
    "    res = np.zeros((n, degree+1))\n",
    "    for i in range(n):\n",
    "        for j in range(d+1):\n",
    "            res[i][j] = np.power(x[i], j)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us play with polynomial regression. Note that we will use your implemented function `compute_mse`. Please copy and paste your implementation from exercise02."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from costs import calculate_mse\n",
    "from plots import *\n",
    "\n",
    "def polynomial_regression():\n",
    "    \"\"\"Constructing the polynomial basis function expansion of the data,\n",
    "       and then running least squares regression.\"\"\"\n",
    "    # define parameters\n",
    "    degrees = [1, 3, 7, 12]\n",
    "    \n",
    "    # define the structure of the figure\n",
    "    num_row = 2\n",
    "    num_col = 2\n",
    "    f, axs = plt.subplots(num_row, num_col)\n",
    "\n",
    "    for ind, degree in enumerate(degrees):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # form the data to do polynomial regression.: TODO\n",
    "        # ***************************************************\n",
    "#         raise NotImplementedError\n",
    "        poly_x = build_poly(x, degree)\n",
    "#         print(np.shape(poly_x))\n",
    "        weights = np.matmul(np.linalg.inv(np.matmul((poly_x.T), poly_x)), poly_x.T).dot(y)\n",
    "        l_mse = calculate_mse(y - poly_x.dot(weights))\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # least square and calculate RMSE: TODO\n",
    "        # ***************************************************\n",
    "#         raise NotImplementedError\n",
    "        \n",
    "        rmse = np.sqrt(2 * l_mse)\n",
    "        print(\"Processing {i}th experiment, degree={d}, rmse={loss}\".format(\n",
    "              i=ind + 1, d=degree, loss=rmse))\n",
    "        # plot fit\n",
    "        plot_fitted_curve(\n",
    "            y, x, weights, degree, axs[ind // num_col][ind % num_col])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"visualize_polynomial_regression\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "Processing 1th experiment, degree=1, rmse=0.47187607963421874\n",
      "64\n",
      "50\n",
      "Processing 2th experiment, degree=3, rmse=0.258582776677375\n",
      "64\n",
      "50\n",
      "Processing 3th experiment, degree=7, rmse=0.24965870360907608\n",
      "64\n",
      "50\n",
      "Processing 4th experiment, degree=12, rmse=0.298581354680811\n",
      "64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1069fff60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "polynomial_regression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Evaluating model predication performance\n",
    "\n",
    "\n",
    "Let us show the train and test splits for various polynomial degrees. First of all, please fill in the function `split_data()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_data(x, y, ratio, seed=1):\n",
    "    \"\"\"\n",
    "    split the dataset based on the split ratio. If ratio is 0.8 \n",
    "    you will have 80% of your data set dedicated to training \n",
    "    and the rest dedicated to testing\n",
    "    \"\"\"\n",
    "    # set seed\n",
    "    np.random.seed(seed)\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # split the data based on the given ratio: TODO\n",
    "    # ***************************************************\n",
    "#     print(np.shape(x))\n",
    "    n = np.shape(x)[0]\n",
    "    random_list = np.random.permutation(list(range(n)))\n",
    "    random_list = random_list[:int(n*ratio)]\n",
    "    training_x = []\n",
    "    testing_x = []\n",
    "    training_y = []\n",
    "    testing_y = []\n",
    "    for i in range(n):\n",
    "        if i in random_list:\n",
    "            training_x.append(x[i])\n",
    "            training_y.append(y[i])\n",
    "        else:\n",
    "            testing_x.append(x[i])\n",
    "            testing_y.append(y[i])\n",
    "    training_x = np.asarray(training_x)\n",
    "    training_y = np.asarray(training_y)\n",
    "    testing_x = np.asarray(testing_x)\n",
    "    testing_y = np.asarray(testing_y)\n",
    "    return training_x, training_y, testing_x, testing_y\n",
    "#     raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, test your `split_data` function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_split_demo(x, y, degree, ratio, seed):\n",
    "    \"\"\"polynomial regression with different split ratios and different degrees.\"\"\"\n",
    "\n",
    "    training_x, training_y, testing_x, testing_y = split_data(x, y, ratio)\n",
    "\n",
    "    training_x_poly = build_poly(training_x, degree)\n",
    "    testing_x_poly = build_poly(testing_x, degree)\n",
    "\n",
    "    weights_tr = np.matmul(np.linalg.inv(np.matmul((training_x_poly.T), training_x_poly)), training_x_poly.T).dot(training_y)\n",
    "    \n",
    "    rmse_tr = np.sqrt(2*calculate_mse(training_y - training_x_poly.dot(weights_tr)))\n",
    "    rmse_te = np.sqrt(2*calculate_mse(testing_y - testing_x_poly.dot(weights_tr)))\n",
    "    print(\"proportion={p}, degree={d}, Training RMSE={tr:.3f}, Testing RMSE={te:.3f}\".format(\n",
    "          p=ratio, d=degree, tr=rmse_tr, te=rmse_te))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "5\n",
      "proportion=0.9, degree=1, Training RMSE=0.455, Testing RMSE=0.621\n",
      "45\n",
      "5\n",
      "proportion=0.9, degree=3, Training RMSE=0.264, Testing RMSE=0.214\n",
      "45\n",
      "5\n",
      "proportion=0.9, degree=7, Training RMSE=0.257, Testing RMSE=0.189\n",
      "45\n",
      "5\n",
      "proportion=0.9, degree=12, Training RMSE=1.721, Testing RMSE=1.542\n",
      "25\n",
      "25\n",
      "proportion=0.5, degree=1, Training RMSE=0.400, Testing RMSE=0.553\n",
      "25\n",
      "25\n",
      "proportion=0.5, degree=3, Training RMSE=0.237, Testing RMSE=0.306\n",
      "25\n",
      "25\n",
      "proportion=0.5, degree=7, Training RMSE=0.218, Testing RMSE=0.336\n",
      "25\n",
      "25\n",
      "proportion=0.5, degree=12, Training RMSE=1.012, Testing RMSE=1.166\n",
      "5\n",
      "45\n",
      "proportion=0.1, degree=1, Training RMSE=0.453, Testing RMSE=0.748\n",
      "5\n",
      "45\n",
      "proportion=0.1, degree=3, Training RMSE=0.111, Testing RMSE=0.674\n",
      "5\n",
      "45\n",
      "proportion=0.1, degree=7, Training RMSE=0.785, Testing RMSE=2.455\n",
      "5\n",
      "45\n",
      "proportion=0.1, degree=12, Training RMSE=3.043, Testing RMSE=324.211\n"
     ]
    }
   ],
   "source": [
    "seed = 6\n",
    "degrees = [1, 3, 7, 12]\n",
    "split_ratios = [0.9, 0.5, 0.1]\n",
    "\n",
    "for split_ratio in split_ratios:\n",
    "    for degree in degrees:\n",
    "        train_test_split_demo(x, y, degree, split_ratio, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Ridge Regression\n",
    "Please fill in the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ridge_regression(y, tx, lambda_):\n",
    "    \"\"\"implement ridge regression.\"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # ridge regression: TODO\n",
    "    # ***************************************************\n",
    "    return np.linalg.inv(tx.T.dot(tx) + (2*tx.shape[0])*lambda_*np.identity(tx.shape[1])).dot(tx.T).dot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ridge_regression_demo(x, y, degree, ratio, seed):\n",
    "    \"\"\"ridge regression demo.\"\"\"\n",
    "    # define parameter\n",
    "    lambdas = np.logspace(-5, 0, 15)\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # split the data, and return train and test data: TODO\n",
    "    # ***************************************************\n",
    "    training_x, training_y, testing_x, testing_y = split_data(x, y, ratio)\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # form train and test data with polynomial basis function: TODO\n",
    "    # ***************************************************\n",
    "    training_x_poly = build_poly(training_x, degree)\n",
    "    testing_x_poly = build_poly(testing_x, degree)\n",
    "\n",
    "    rmse_tr = []\n",
    "    rmse_te = []\n",
    "    for ind, lambda_ in enumerate(lambdas):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # ridge regression with a given lambda\n",
    "        # ***************************************************\n",
    "        w_train = ridge_regression(training_y, training_x_poly, lambda_)\n",
    "#         print(w_train)\n",
    "        e_train = training_y - training_x_poly.dot(w_train)\n",
    "        e_test = testing_y - testing_x_poly.dot(w_train)\n",
    "        rmse_tr.append(np.sqrt(2 * calculate_mse(e_train)))\n",
    "        rmse_te.append(np.sqrt(2 * calculate_mse(e_test)))\n",
    "        print(\"proportion={p}, degree={d}, lambda={l:.3f}, Training RMSE={tr:.3f}, Testing RMSE={te:.3f}\".format(\n",
    "               p=ratio, d=degree, l=lambda_, tr=rmse_tr[ind], te=rmse_te[ind]))\n",
    "        \n",
    "    # Plot the obtained results\n",
    "    plot_train_test(rmse_tr, rmse_te, lambdas, degree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "25\n",
      "proportion=0.5, degree=7, lambda=0.000, Training RMSE=0.220, Testing RMSE=0.319\n",
      "proportion=0.5, degree=7, lambda=0.000, Training RMSE=0.222, Testing RMSE=0.319\n",
      "proportion=0.5, degree=7, lambda=0.000, Training RMSE=0.225, Testing RMSE=0.322\n",
      "proportion=0.5, degree=7, lambda=0.000, Training RMSE=0.226, Testing RMSE=0.325\n",
      "proportion=0.5, degree=7, lambda=0.000, Training RMSE=0.227, Testing RMSE=0.327\n",
      "proportion=0.5, degree=7, lambda=0.001, Training RMSE=0.228, Testing RMSE=0.329\n",
      "proportion=0.5, degree=7, lambda=0.001, Training RMSE=0.228, Testing RMSE=0.329\n",
      "proportion=0.5, degree=7, lambda=0.003, Training RMSE=0.229, Testing RMSE=0.327\n",
      "proportion=0.5, degree=7, lambda=0.007, Training RMSE=0.229, Testing RMSE=0.319\n",
      "proportion=0.5, degree=7, lambda=0.016, Training RMSE=0.232, Testing RMSE=0.302\n",
      "proportion=0.5, degree=7, lambda=0.037, Training RMSE=0.239, Testing RMSE=0.279\n",
      "proportion=0.5, degree=7, lambda=0.085, Training RMSE=0.259, Testing RMSE=0.266\n",
      "proportion=0.5, degree=7, lambda=0.193, Training RMSE=0.297, Testing RMSE=0.294\n",
      "proportion=0.5, degree=7, lambda=0.439, Training RMSE=0.342, Testing RMSE=0.344\n",
      "proportion=0.5, degree=7, lambda=1.000, Training RMSE=0.380, Testing RMSE=0.374\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEaCAYAAAACBmAUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x105e8dda0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seed = 56\n",
    "degree = 7\n",
    "split_ratio = 0.5\n",
    "ridge_regression_demo(x, y, degree, split_ratio, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
